# Level 5: Architectural Mapping (The Scenario Layer)

> Map the right database technology to the right use case. This is where theory meets practice.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ—ºï¸  HOW THIS LEVEL CONNECTS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  LEVEL 5: ARCHITECTURAL MAPPING â—„â”€â”€ YOU ARE HERE                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚  Scope: Choosing the RIGHT tool for the job                                 â”‚
â”‚  Focus: Database selection, trade-offs, real-world scenarios               â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                   ALL PREVIOUS LEVELS COME TOGETHER                     â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  PostgreSQL: Why choose it?                                             â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: Uses B-Tree (read-optimized)                              â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: Strong ACID, full isolation levels                        â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Streaming replication (but limited sharding)              â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: Logical replication for CDC                               â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  Cassandra: Why choose it?                                              â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: Uses LSM-Tree (write-optimized)                           â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: Tunable consistency (not full ACID)                       â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Built for distribution, peer-to-peer                      â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: CDC via Debezium connector                                â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  Redis: Why choose it?                                                  â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: In-memory (no disk I/O for reads!)                        â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: No transactions (simple key-value)                        â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Cluster mode, async replication (AP system)               â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: Pub/Sub for real-time fan-out                             â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  Kafka: Why choose it?                                                  â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: Append-only log (sequential writes)                       â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: Ordering within partition                                 â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Distributed, replicated, fault-tolerant                   â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: THE backbone for CDC and event streaming                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  THIS IS THE "SYSTEM DESIGN INTERVIEW" LEVEL:                               â”‚
â”‚  â€¢ "What database would you use for X?" - Answer with trade-offs           â”‚
â”‚  â€¢ "Why not use MongoDB?" - Explain CAP/PACELC implications                â”‚
â”‚  â€¢ "How would you scale this?" - Combine sharding + caching + queuing      â”‚
â”‚                                                                              â”‚
â”‚  APPLIES TO:                                                                â”‚
â”‚  âœ… Every system design question!                                           â”‚
â”‚  âœ… This is where you demonstrate senior-level thinking                     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Table of Contents
1. [PostgreSQL/MySQL](#1-postgresqlmysql)
2. [Cassandra](#2-cassandra)
3. [Redis](#3-redis)
4. [Kafka](#4-kafka)
5. [OLTP vs OLAP](#5-oltp-vs-olap)
6. [Blob/Object Storage](#6-blobobject-storage)
7. [Decision Matrix](#7-decision-matrix)

---

## 1. PostgreSQL/MySQL

### Core Identity

| Aspect | PostgreSQL | MySQL |
|--------|------------|-------|
| **Architecture** | Process-per-connection | Thread-per-connection |
| **MVCC** | Heap-based (needs VACUUM) | Undo log-based |
| **Replication** | Streaming (WAL) | Binary log |
| **JSON Support** | Native JSONB | JSON type |
| **Best For** | Complex queries, data integrity | High read throughput |

### CAP/PACELC Classification

```
SINGLE NODE: CA (no partition tolerance)
WITH SYNC REPLICATION: CP / PC/EC
  - During partition: Writes blocked (Consistency over Availability)
  - Normal operation: Consistent, higher latency (wait for replica ACK)

WITH ASYNC REPLICATION: AP / PA/EL  
  - During partition: Writes continue on primary
  - Normal operation: Fast, eventual consistency
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Financial transactions (ACID guarantees)
â”œâ”€â”€ E-commerce orders (complex relations, consistency)
â”œâ”€â”€ User accounts & authentication
â”œâ”€â”€ Content management (rich queries)
â””â”€â”€ Any system where consistency > availability

âš ï¸ LIMITATIONS:
â”œâ”€â”€ Single-node write throughput ceiling (~10K-50K TPS)
â”œâ”€â”€ Scaling reads: Add replicas
â”œâ”€â”€ Scaling writes: Vertical only (or application-level sharding)
â””â”€â”€ Not ideal for: Time-series, IoT, massive write loads
```

### Interview Talking Points

```
"We use PostgreSQL for our user and order data because:
1. ACID transactions ensure money never disappears
2. Foreign keys maintain referential integrity
3. Complex JOIN queries for reporting
4. JSONB for flexible attributes without schema changes

For scaling, we use:
- Read replicas for query distribution
- Connection pooling (PgBouncer) for efficiency
- Application-level sharding by tenant_id if needed"
```

---

## 2. Cassandra

### Core Identity

| Aspect | Details |
|--------|---------|
| **Data Model** | Wide-column (partition key + clustering columns) |
| **Storage** | LSM-Tree (write-optimized) |
| **Consistency** | Tunable (ONE to ALL) |
| **Replication** | Peer-to-peer, no single leader |
| **Query Language** | CQL (SQL-like, but limited) |

### CAP/PACELC Classification

```
CAP: AP (Available during Partition)
PACELC: PA/EL (Prioritize Availability and Low Latency)

Default consistency: LOCAL_ONE (fast but weak)
Can tune per-query: QUORUM, ALL (stronger but slower)

Trade-off knobs:
- Replication Factor: 3 (typical)
- Write Consistency: QUORUM = 2/3 must ACK
- Read Consistency: QUORUM = 2/3 must respond
- For strong consistency: R + W > N
```

### Data Model Design

```
CASSANDRA DESIGN PRINCIPLE: Model for your queries, not your entities

âŒ WRONG (relational thinking):
  users(id, name, email)
  orders(id, user_id, product, time)
  
  SELECT * FROM orders WHERE user_id = 123 ORDER BY time DESC
  â†’ Requires secondary index, SLOW

âœ… RIGHT (query-driven):
  orders_by_user(user_id, time, order_id, product)
  PRIMARY KEY ((user_id), time)
  
  â†’ user_id is partition key (data locality)
  â†’ time is clustering column (sorted within partition)
  â†’ Query is a single partition scan, FAST
```

### Primary Key = Partition Key + Clustering Key

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“– DETAILED COVERAGE: See Level 2 - Database Logic                        â”‚
â”‚     Section: "NoSQL Indexing: Partition Key, Clustering Key & Secondary    â”‚
â”‚              Indexes"                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  QUICK REFERENCE:                                                            â”‚
â”‚                                                                              â”‚
â”‚  PRIMARY KEY ((partition_key), clustering_key1, clustering_key2, ...)       â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                      â”‚                            â”‚                          â”‚
â”‚            PARTITION KEY                  CLUSTERING COLUMNS                 â”‚
â”‚         (WHERE data lives)              (HOW data is sorted)                â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     PARTITION KEY       â”‚         CLUSTERING KEY                     â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Determines WHICH NODE   â”‚ Determines SORT ORDER within partition     â”‚  â”‚
â”‚  â”‚ MUST be in WHERE (=)    â”‚ Optional, enables range queries (<, >)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  EXAMPLE:                                                                    â”‚
â”‚  CREATE TABLE messages (                                                     â”‚
â”‚      chat_id UUID,                                                           â”‚
â”‚      sent_at TIMESTAMP,                                                      â”‚
â”‚      content TEXT,                                                           â”‚
â”‚      PRIMARY KEY ((chat_id), sent_at)  â† chat_id: partition, sent_at: sort  â”‚
â”‚  );                                                                          â”‚
â”‚                                                                              â”‚
â”‚  âœ… FAST: WHERE chat_id = 'abc' AND sent_at > '2024-01-15'                  â”‚
â”‚  âŒ SLOW: WHERE sent_at > '2024-01-15' (no partition key = cluster scan!)   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DynamoDB Terminology

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Cassandra      â”‚      DynamoDB      â”‚      Meaning       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Partition Key    â”‚   Partition Key    â”‚ Where data lives   â”‚
â”‚   Clustering Key   â”‚    Sort Key        â”‚ Order within       â”‚
â”‚   Primary Key      â”‚   Composite Key    â”‚ PK + SK together   â”‚
â”‚   Secondary Index  â”‚   LSI / GSI        â”‚ Query on non-keys  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ‘‰ For full coverage of LSI vs GSI trade-offs, see Level 2 - Database Logic.
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Time-series data (IoT sensors, metrics)
â”œâ”€â”€ Event logging (append-only, massive scale)
â”œâ”€â”€ Messaging (inbox per user)
â”œâ”€â”€ Recommendations (pre-computed per user)
â””â”€â”€ Any write-heavy, read-by-key workload

âš ï¸ LIMITATIONS:
â”œâ”€â”€ No JOINs (denormalize everything)
â”œâ”€â”€ No ad-hoc queries (design tables per query)
â”œâ”€â”€ Deletes are expensive (tombstones)
â”œâ”€â”€ Secondary indexes are limited
â””â”€â”€ Not for: Complex queries, small datasets, strong consistency
```

### Interview Talking Points

```
"We use Cassandra for our event logging because:
1. 100K+ writes/sec across the cluster
2. Time-series data is append-only (LSM-Tree sweet spot)
3. Partition by (device_id, day) for data locality
4. Cluster by timestamp for efficient range queries
5. Tunable consistency: ONE for writes, QUORUM for reads

We accept eventual consistency because:
- Logs don't need strong consistency
- We can tolerate seconds of lag
- Availability is more important than perfect ordering"
```

---

## 3. Redis

### Core Identity

| Aspect | Details |
|--------|---------|
| **Storage** | In-memory (with optional persistence) |
| **Data Structures** | Strings, Lists, Sets, Hashes, Sorted Sets, Streams |
| **Latency** | Sub-millisecond |
| **Persistence** | RDB (snapshots) / AOF (append-only log) |
| **Clustering** | Redis Cluster (hash slots) |

### CAP/PACELC Classification

```
CAP: AP (in cluster mode, prioritizes availability)
PACELC: PA/EL (fast and available)

Replication: Asynchronous
- Primary failure can lose recent writes
- For durability: Use WAIT command or accept loss

Cluster mode:
- 16384 hash slots distributed across nodes
- Client routes to correct node
- Failover via Sentinel or Cluster consensus
```

### Key Patterns

```
1. CACHE-ASIDE
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ read(key):                                  â”‚
   â”‚   value = redis.get(key)                    â”‚
   â”‚   if value is None:                         â”‚
   â”‚       value = db.query(key)                 â”‚
   â”‚       redis.setex(key, TTL, value)          â”‚
   â”‚   return value                              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. WRITE-THROUGH
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ write(key, value):                          â”‚
   â”‚   db.insert(key, value)                     â”‚
   â”‚   redis.set(key, value)                     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. RATE LIMITING (Sliding Window)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ZADD rate:{ip} {timestamp} {request_id}     â”‚
   â”‚ ZREMRANGEBYSCORE rate:{ip} 0 {timestamp-60} â”‚
   â”‚ ZCARD rate:{ip} â†’ count in last 60 seconds  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. DISTRIBUTED LOCK (Redlock)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ SET lock:{resource} {token} NX PX 30000     â”‚
   â”‚ # NX = only if not exists                   â”‚
   â”‚ # PX = expire in 30 seconds                 â”‚
   â”‚ # token = unique identifier for unlock      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5. LEADERBOARD (Sorted Set)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ZADD leaderboard {score} {user_id}          â”‚
   â”‚ ZREVRANGE leaderboard 0 9 WITHSCORES        â”‚
   â”‚ â†’ Top 10 users by score, O(log N) updates   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Caching (session, query results, computed data)
â”œâ”€â”€ Rate limiting
â”œâ”€â”€ Leaderboards / rankings
â”œâ”€â”€ Real-time analytics counters
â”œâ”€â”€ Pub/Sub messaging
â”œâ”€â”€ Distributed locks
â””â”€â”€ Queue (with Redis Streams)

âš ï¸ LIMITATIONS:
â”œâ”€â”€ Data must fit in memory (expensive at scale)
â”œâ”€â”€ Persistence options have trade-offs
â”œâ”€â”€ Not a primary data store
â”œâ”€â”€ Cluster adds complexity
â””â”€â”€ Not for: Large datasets, durable storage, complex queries
```

### Interview Talking Points

```
"We use Redis as our caching layer because:
1. Sub-millisecond latency for hot data
2. Reduces database load by 90%+
3. Native data structures (sorted sets for leaderboards)
4. TTL-based expiration for cache freshness

Cache invalidation strategy:
- CDC events trigger cache deletes
- TTL as a safety net
- Cache-aside for reads

For distributed locks:
- Redlock algorithm across 5 Redis instances
- Fencing tokens for safety"
```

---

## 4. Kafka

### Core Identity

| Aspect | Details |
|--------|---------|
| **Model** | Distributed commit log |
| **Storage** | Append-only log on disk |
| **Ordering** | Per-partition ordering guaranteed |
| **Retention** | Time-based or size-based |
| **Consumers** | Pull-based with consumer groups |

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         KAFKA CLUSTER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  TOPIC: orders (3 partitions, replication factor 2)                 â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Partition 0 â”‚  â”‚ Partition 1 â”‚  â”‚ Partition 2 â”‚                 â”‚
â”‚  â”‚ Leader: B1  â”‚  â”‚ Leader: B2  â”‚  â”‚ Leader: B3  â”‚                 â”‚
â”‚  â”‚ Replica: B2 â”‚  â”‚ Replica: B3 â”‚  â”‚ Replica: B1 â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚        â”‚                â”‚                â”‚                          â”‚
â”‚        â–¼                â–¼                â–¼                          â”‚
â”‚  [msg1,msg4,...]  [msg2,msg5,...]  [msg3,msg6,...]                  â”‚
â”‚                                                                      â”‚
â”‚  PARTITIONING:                                                       â”‚
â”‚  â€¢ Default: Round-robin                                             â”‚
â”‚  â€¢ With key: hash(key) % num_partitions                             â”‚
â”‚  â€¢ Messages with same key â†’ same partition â†’ ordering guaranteed    â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Consumer Groups

```
CONSUMER GROUP: order-processors

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                      â”‚
â”‚  Partition 0 â”€â”€â”€â”€â”€â”€â–º Consumer A                                     â”‚
â”‚  Partition 1 â”€â”€â”€â”€â”€â”€â–º Consumer B                                     â”‚
â”‚  Partition 2 â”€â”€â”€â”€â”€â”€â–º Consumer C                                     â”‚
â”‚                                                                      â”‚
â”‚  â€¢ Each partition assigned to ONE consumer in a group               â”‚
â”‚  â€¢ Add consumers (up to partition count) for parallelism            â”‚
â”‚  â€¢ Consumer failure â†’ partition reassigned to another               â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MULTIPLE GROUPS (Fan-out):

Topic: orders
â”œâ”€â”€ Consumer Group: analytics-pipeline
â”‚   â””â”€â”€ Reads all messages for analytics
â”œâ”€â”€ Consumer Group: notification-service  
â”‚   â””â”€â”€ Reads all messages for emails
â””â”€â”€ Consumer Group: inventory-service
    â””â”€â”€ Reads all messages to update stock
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Event sourcing (immutable event log)
â”œâ”€â”€ Stream processing (real-time pipelines)
â”œâ”€â”€ Microservices communication (decoupling)
â”œâ”€â”€ Log aggregation
â”œâ”€â”€ CDC destination (from Debezium)
â””â”€â”€ Message replay (re-process historical events)

âš ï¸ LIMITATIONS:
â”œâ”€â”€ Not a database (no queries, only sequential read)
â”œâ”€â”€ Not for request-response (use HTTP)
â”œâ”€â”€ Ordering only within partition
â”œâ”€â”€ Operational complexity (Zookeeper/KRaft, brokers)
â””â”€â”€ Latency higher than direct calls
```

### Interview Talking Points

```
"We use Kafka as the backbone of our event-driven architecture:

1. Decoupling: Services publish events, don't know consumers
2. Durability: Events stored for 7 days, replay if needed
3. Scaling: Add partitions for throughput, consumers for parallelism
4. Ordering: Partition by user_id so user events processed in order

Key patterns:
- Outbox pattern: Write to DB + outbox, Debezium â†’ Kafka
- Saga orchestration: Kafka connects saga steps
- CQRS: Commands via HTTP, events via Kafka to read model"
```

---

## 5. OLTP vs OLAP

### The Two Worlds of Data Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OLTP vs OLAP                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  OLTP (Online Transaction Processing)                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  "The application database"                                                  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ INSERT this order                                                         â”‚
â”‚  â€¢ UPDATE user's email                                                       â”‚
â”‚  â€¢ SELECT user WHERE id = 123                                               â”‚
â”‚                                                                              â”‚
â”‚  Characteristics:                                                            â”‚
â”‚  â€¢ Short queries, few rows affected                                         â”‚
â”‚  â€¢ High concurrency (1000s of users)                                        â”‚
â”‚  â€¢ Low latency required (ms)                                                â”‚
â”‚  â€¢ Row-oriented storage                                                      â”‚
â”‚  â€¢ Normalized schema (3NF)                                                   â”‚
â”‚                                                                              â”‚
â”‚  Examples: PostgreSQL, MySQL, Oracle                                        â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  OLAP (Online Analytical Processing)                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  "The analytics database"                                                    â”‚
â”‚                                                                              â”‚
â”‚  â€¢ What was total revenue last quarter by region?                           â”‚
â”‚  â€¢ Which products have declining sales trend?                               â”‚
â”‚  â€¢ Customer cohort analysis over 2 years                                    â”‚
â”‚                                                                              â”‚
â”‚  Characteristics:                                                            â”‚
â”‚  â€¢ Long queries, millions of rows scanned                                   â”‚
â”‚  â€¢ Low concurrency (few analysts)                                           â”‚
â”‚  â€¢ High latency acceptable (seconds to minutes)                             â”‚
â”‚  â€¢ Column-oriented storage                                                   â”‚
â”‚  â€¢ Denormalized schema (Star/Snowflake)                                     â”‚
â”‚                                                                              â”‚
â”‚  Examples: Snowflake, BigQuery, Redshift, ClickHouse                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Side-by-Side Comparison

| Aspect | OLTP | OLAP |
|--------|------|------|
| **Purpose** | Run the business | Analyze the business |
| **Users** | Customers, apps | Analysts, data scientists |
| **Queries** | Simple, predefined | Complex, ad-hoc |
| **Data Size** | GBs to TBs | TBs to PBs |
| **Freshness** | Real-time | Hourly/daily batch |
| **Schema** | Normalized (3NF) | Denormalized (Star) |
| **Storage** | Row-oriented | Column-oriented |
| **Concurrency** | 1000s | 10s |
| **Latency** | Milliseconds | Seconds to minutes |

### Row vs Column Storage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ROW vs COLUMN STORAGE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  TABLE: sales (id, date, product, region, amount)                           â”‚
â”‚                                                                              â”‚
â”‚  ROW-ORIENTED (OLTP - PostgreSQL, MySQL):                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Stored as: [row1_all_columns][row2_all_columns][row3_all_columns]...       â”‚
â”‚                                                                              â”‚
â”‚  Disk:                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1|2024-01-15|Widget|US|100 â”‚ 2|2024-01-15|Gadget|EU|200 â”‚ ...      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  âœ… GOOD FOR: Fetch entire row (SELECT * WHERE id=1)                        â”‚
â”‚  âŒ BAD FOR: Aggregate one column (SUM(amount) for 1B rows)                 â”‚
â”‚              Must read ALL columns to get one column!                       â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  COLUMN-ORIENTED (OLAP - ClickHouse, Redshift, Parquet):                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Stored as: [all_ids][all_dates][all_products][all_regions][all_amounts]    â”‚
â”‚                                                                              â”‚
â”‚  Disk:                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ IDs:     1, 2, 3, 4, 5, ...                                         â”‚    â”‚
â”‚  â”‚ Dates:   2024-01-15, 2024-01-15, 2024-01-16, ...                    â”‚    â”‚
â”‚  â”‚ Products: Widget, Gadget, Widget, ...                               â”‚    â”‚
â”‚  â”‚ Regions: US, EU, US, ...                                            â”‚    â”‚
â”‚  â”‚ Amounts: 100, 200, 150, ...  â† Only read this for SUM!              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  âœ… GOOD FOR: Aggregate queries (read only columns needed)                  â”‚
â”‚  âœ… GOOD FOR: Compression (similar values together)                         â”‚
â”‚  âŒ BAD FOR: Fetch single row (must read from many files)                   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Warehouse Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TYPICAL DATA WAREHOUSE FLOW                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  SOURCES              ETL/ELT           WAREHOUSE          CONSUMPTION       â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ PostgreSQLâ”‚â”€â”€â”    â”‚          â”‚      â”‚              â”‚   â”‚ Dashboardsâ”‚     â”‚
â”‚  â”‚  (OLTP)   â”‚  â”‚    â”‚  Spark   â”‚      â”‚  Snowflake   â”‚   â”‚ (Tableau) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  Airflow â”‚      â”‚  Redshift    â”‚â”€â”€â–ºâ”‚           â”‚     â”‚
â”‚                â”‚â”€â”€â”€â–ºâ”‚  dbt     â”‚â”€â”€â”€â”€â”€â–ºâ”‚  BigQuery    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚          â”‚      â”‚              â”‚                     â”‚
â”‚  â”‚   Kafka   â”‚â”€â”€â”¤    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  ClickHouse  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  (Events) â”‚  â”‚                      â”‚              â”‚   â”‚ ML Modelsâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â–ºâ”‚           â”‚     â”‚
â”‚                â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                                                           â”‚
â”‚  â”‚   S3     â”‚â”€â”€â”˜                                                           â”‚
â”‚  â”‚  (Logs)  â”‚                                                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### HDFS & Big Data Storage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HDFS (Hadoop Distributed File System)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  WHAT: Distributed file system for storing massive datasets                 â”‚
â”‚  WHEN: Petabyte-scale storage, batch processing                             â”‚
â”‚                                                                              â”‚
â”‚  ARCHITECTURE:                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                       NAMENODE (Master)                                 â”‚â”‚
â”‚  â”‚           Stores metadata: which blocks are where                       â”‚â”‚
â”‚  â”‚           Single point of failure (use HA NameNode!)                    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                    /              |              \                          â”‚
â”‚                   /               |               \                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   DATANODE 1    â”‚  â”‚   DATANODE 2    â”‚  â”‚   DATANODE 3    â”‚             â”‚
â”‚  â”‚ Block A (copy 1)â”‚  â”‚ Block A (copy 2)â”‚  â”‚ Block A (copy 3)â”‚             â”‚
â”‚  â”‚ Block B (copy 1)â”‚  â”‚ Block C (copy 1)â”‚  â”‚ Block B (copy 2)â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                              â”‚
â”‚  KEY CONCEPTS:                                                               â”‚
â”‚  â€¢ Files split into BLOCKS (default 128MB)                                  â”‚
â”‚  â€¢ Each block replicated 3x across DataNodes                                â”‚
â”‚  â€¢ Write-once, read-many (immutable files)                                  â”‚
â”‚  â€¢ "Move compute to data" (run jobs where data lives)                       â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  FILE FORMATS ON HDFS:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Format     â”‚   Description                                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚   Parquet    â”‚   Columnar, best for analytics, high compression      â”‚  â”‚
â”‚  â”‚   ORC        â”‚   Columnar, optimized for Hive, good compression      â”‚  â”‚
â”‚  â”‚   Avro       â”‚   Row-based, good for streaming, schema evolution     â”‚  â”‚
â”‚  â”‚   CSV/JSON   â”‚   Human-readable, poor performance, avoid at scale    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  MODERN ALTERNATIVES:                                                        â”‚
â”‚  â€¢ S3 + query engines (Spark, Presto, Athena) replacing HDFS               â”‚
â”‚  â€¢ Delta Lake, Iceberg, Hudi (ACID on object storage)                       â”‚
â”‚  â€¢ Databricks, Snowflake (managed solutions)                                â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OLAP Databases Comparison

| Database | Type | Best For |
|----------|------|----------|
| **ClickHouse** | Column-store | Real-time analytics, time-series |
| **Snowflake** | Cloud DW | General analytics, variable workloads |
| **BigQuery** | Serverless | Ad-hoc queries, Google ecosystem |
| **Redshift** | Cloud DW | AWS ecosystem, Postgres-compatible |
| **Druid** | Real-time OLAP | Sub-second queries on streaming data |
| **Presto/Trino** | Query engine | Federated queries across sources |
| **Spark SQL** | Batch processing | ETL, ML pipelines |

---

## 6. Blob/Object Storage

### What is Object Storage?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBJECT STORAGE vs FILE STORAGE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  FILE STORAGE (NFS, EFS):                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  /home/                                                                      â”‚
â”‚  â”œâ”€â”€ user1/                                                                  â”‚
â”‚  â”‚   â”œâ”€â”€ documents/                                                         â”‚
â”‚  â”‚   â”‚   â””â”€â”€ report.pdf                                                     â”‚
â”‚  â”‚   â””â”€â”€ photos/                                                            â”‚
â”‚  â”‚       â””â”€â”€ vacation.jpg                                                   â”‚
â”‚  â””â”€â”€ user2/                                                                  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Hierarchical (directories and files)                                     â”‚
â”‚  â€¢ Supports file locking, permissions                                        â”‚
â”‚  â€¢ Limited scalability                                                       â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  OBJECT STORAGE (S3, GCS, Azure Blob):                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Bucket: my-app-data                                                         â”‚
â”‚  Objects:                                                                    â”‚
â”‚    â€¢ Key: "users/123/profile.jpg"  â†’ Binary data + metadata                 â”‚
â”‚    â€¢ Key: "users/123/resume.pdf"   â†’ Binary data + metadata                 â”‚
â”‚    â€¢ Key: "logs/2024/01/15/app.log"â†’ Binary data + metadata                 â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Flat namespace (key â†’ value)                                             â”‚
â”‚  â€¢ "/" in key is just a character (no real directories!)                    â”‚
â”‚  â€¢ Immutable objects (versioning optional)                                  â”‚
â”‚  â€¢ Virtually unlimited scalability                                          â”‚
â”‚  â€¢ Eventual consistency (historically, now often strong)                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Use Object Storage

```
âœ… PERFECT FOR:
â”œâ”€â”€ User-generated content (images, videos, documents)
â”œâ”€â”€ Static assets (JS, CSS, images for web apps)
â”œâ”€â”€ Backups and archives
â”œâ”€â”€ Data lake storage (Parquet files for analytics)
â”œâ”€â”€ Log storage
â””â”€â”€ ML training data and models

âŒ NOT FOR:
â”œâ”€â”€ Transactional data (use a database)
â”œâ”€â”€ Frequently updated small files (high latency)
â”œâ”€â”€ Data requiring file locking
â””â”€â”€ Low-latency access patterns (consider caching)
```

### Object Storage Services Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBJECT STORAGE OPTIONS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  AWS S3 (Simple Storage Service)                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ The "standard" (S3 API is de-facto industry standard)                    â”‚
â”‚  â€¢ Storage classes: Standard, Infrequent Access, Glacier (archival)         â”‚
â”‚  â€¢ Strong consistency (as of Dec 2020)                                      â”‚
â”‚  â€¢ Integrates with entire AWS ecosystem                                     â”‚
â”‚  â€¢ Pricing: ~$0.023/GB/month (Standard)                                     â”‚
â”‚                                                                              â”‚
â”‚  Google Cloud Storage (GCS)                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ S3-compatible API available                                              â”‚
â”‚  â€¢ Storage classes: Standard, Nearline, Coldline, Archive                   â”‚
â”‚  â€¢ Strong consistency                                                        â”‚
â”‚  â€¢ Best for: Google Cloud / BigQuery users                                  â”‚
â”‚                                                                              â”‚
â”‚  Azure Blob Storage                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Hot, Cool, Archive tiers                                                 â”‚
â”‚  â€¢ Best for: Azure ecosystem, Microsoft shops                               â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  LinkedIn Ambry                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ LinkedIn's open-source blob storage                                      â”‚
â”‚  â€¢ Designed for immutable media (images, videos)                            â”‚
â”‚  â€¢ Low latency, high throughput                                             â”‚
â”‚  â€¢ On-premise, not a cloud service                                          â”‚
â”‚  â€¢ Use case: Social media platforms with massive media                      â”‚
â”‚                                                                              â”‚
â”‚  MinIO                                                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ S3-compatible, self-hosted object storage                                â”‚
â”‚  â€¢ Open source, can run on Kubernetes                                       â”‚
â”‚  â€¢ Use case: On-premise, hybrid cloud, development                          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### S3 Access Patterns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMMON S3 PATTERNS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. DIRECT UPLOAD (Pre-signed URLs)                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  Client â”€â”€â–º Your API â”€â”€â–º Generate Pre-signed URL                            â”‚
â”‚    â”‚                            â”‚                                            â”‚
â”‚    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚    â”‚         â”‚                                                               â”‚
â”‚    â”‚         â–¼                                                               â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â–º S3 (direct upload, bypasses your server)                        â”‚
â”‚                                                                              â”‚
â”‚  WHY: Don't proxy large files through your servers                          â”‚
â”‚                                                                              â”‚
â”‚  2. CDN IN FRONT (CloudFront + S3)                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  Client â”€â”€â–º CloudFront (CDN) â”€â”€â–º S3 (origin)                                â”‚
â”‚              â”‚                                                               â”‚
â”‚              â””â”€â”€ Caches at edge locations worldwide                          â”‚
â”‚                                                                              â”‚
â”‚  WHY: Reduce latency, reduce S3 costs (fewer requests)                      â”‚
â”‚                                                                              â”‚
â”‚  3. LIFECYCLE POLICIES                                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  Day 0:   Object in S3 Standard ($0.023/GB)                                 â”‚
â”‚  Day 30:  Auto-transition to Infrequent Access ($0.0125/GB)                 â”‚
â”‚  Day 90:  Auto-transition to Glacier ($0.004/GB)                            â”‚
â”‚  Day 365: Auto-delete                                                        â”‚
â”‚                                                                              â”‚
â”‚  WHY: Automatic cost optimization for aging data                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interview Talking Points

```
"For user-uploaded images, we:
1. Generate a pre-signed S3 URL (client uploads directly)
2. Store metadata (user_id, filename, size) in PostgreSQL
3. Serve via CloudFront CDN for low latency
4. Use lifecycle policies: Standard â†’ IA after 30 days â†’ Glacier after 1 year

For our data lake:
1. Store raw events in S3 as Parquet files (columnar, compressed)
2. Partition by date: s3://data-lake/events/year=2024/month=01/day=15/
3. Query with Athena/Spark (no data movement)
4. Use Delta Lake for ACID transactions on object storage"
```

---

## 7. Decision Matrix

### Quick Reference Table

| Requirement | PostgreSQL | Cassandra | Redis | Kafka |
|-------------|------------|-----------|-------|-------|
| ACID Transactions | âœ… | âŒ | âŒ | âŒ |
| Complex Queries | âœ… | âŒ | âŒ | âŒ |
| High Write Throughput | âš ï¸ | âœ… | âœ… | âœ… |
| Low Latency Reads | âš ï¸ | âš ï¸ | âœ… | âŒ |
| Horizontal Scale | âš ï¸ | âœ… | âš ï¸ | âœ… |
| Durability | âœ… | âœ… | âš ï¸ | âœ… |
| Global Distribution | âš ï¸ | âœ… | âš ï¸ | âš ï¸ |
| Message Replay | âŒ | âŒ | âŒ | âœ… |

### Scenario-Based Selection

```
SCENARIO 1: E-Commerce Platform
â”œâ”€â”€ User accounts: PostgreSQL (ACID, complex queries)
â”œâ”€â”€ Product catalog: PostgreSQL + Elasticsearch (search)
â”œâ”€â”€ Shopping cart: Redis (fast, ephemeral)
â”œâ”€â”€ Order processing: PostgreSQL (transactions)
â”œâ”€â”€ Order events: Kafka (decouple inventory, shipping)
â””â”€â”€ Session storage: Redis (fast, TTL)

SCENARIO 2: Social Media Feed
â”œâ”€â”€ User profiles: PostgreSQL (relations, consistency)
â”œâ”€â”€ Posts: PostgreSQL (source of truth)
â”œâ”€â”€ Timeline cache: Redis (pre-computed feeds)
â”œâ”€â”€ Post events: Kafka (fan-out workers)
â”œâ”€â”€ Activity stream: Cassandra (time-series, write-heavy)
â””â”€â”€ Real-time updates: Redis Pub/Sub â†’ WebSocket

SCENARIO 3: IoT Sensor Platform
â”œâ”€â”€ Device registry: PostgreSQL (relations)
â”œâ”€â”€ Sensor readings: Cassandra (massive writes, time-series)
â”œâ”€â”€ Real-time dashboard: Redis (aggregations)
â”œâ”€â”€ Event pipeline: Kafka (sensor â†’ processing â†’ storage)
â””â”€â”€ Alerts: Kafka â†’ Alert service

SCENARIO 4: Financial Trading
â”œâ”€â”€ Accounts/Balances: PostgreSQL (ACID!)
â”œâ”€â”€ Trade execution: PostgreSQL (serializable transactions)
â”œâ”€â”€ Market data: Kafka (streaming prices)
â”œâ”€â”€ Order book cache: Redis (low latency)
â”œâ”€â”€ Audit log: Cassandra (append-only)
â””â”€â”€ Real-time prices: Kafka â†’ WebSocket
```

---

## Interview Checklist

### Questions You Should Be Able to Answer

- [ ] "Why PostgreSQL and not Cassandra for user accounts?"
- [ ] "When would you choose Cassandra over PostgreSQL?"
- [ ] "Why use Redis when PostgreSQL can also cache?"
- [ ] "What's the difference between Redis and Kafka Pub/Sub?"
- [ ] "How would you design a system using all four?"

### Common Mistakes

| Mistake | Why It's Wrong |
|---------|----------------|
| "Kafka as a database" | Kafka is a log, not for queries |
| "Redis as primary storage" | Memory-only, use as cache layer |
| "Cassandra for transactions" | No ACID, use PostgreSQL |
| "PostgreSQL for 1M writes/sec" | Single-node limit, use Cassandra |

---

## Next Steps

Continue to **[Level 6: Senior Gotchas](06_SENIOR_GOTCHAS.md)** for edge case interview questions.

