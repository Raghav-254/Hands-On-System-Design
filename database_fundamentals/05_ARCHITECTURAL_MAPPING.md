# Level 5: Architectural Mapping (The Scenario Layer)

> Map the right database technology to the right use case. This is where theory meets practice.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ—ºï¸  HOW THIS LEVEL CONNECTS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  LEVEL 5: ARCHITECTURAL MAPPING â—„â”€â”€ YOU ARE HERE                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚  Scope: Choosing the RIGHT tool for the job                                 â”‚
â”‚  Focus: Database selection, trade-offs, real-world scenarios               â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                   ALL PREVIOUS LEVELS COME TOGETHER                     â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  PostgreSQL: Why choose it?                                             â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: Uses B-Tree (read-optimized)                              â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: Strong ACID, full isolation levels                        â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Streaming replication (but limited sharding)              â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: Logical replication for CDC                               â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  Cassandra: Why choose it?                                              â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: Uses LSM-Tree (write-optimized)                           â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: Tunable consistency (not full ACID)                       â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Built for distribution, peer-to-peer                      â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: CDC via Debezium connector                                â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  Redis: Why choose it?                                                  â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: In-memory (no disk I/O for reads!)                        â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: No transactions (simple key-value)                        â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Cluster mode, async replication (AP system)               â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: Pub/Sub for real-time fan-out                             â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  Kafka: Why choose it?                                                  â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: Append-only log (sequential writes)                       â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: Ordering within partition                                 â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Distributed, replicated, fault-tolerant                   â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: THE backbone for CDC and event streaming                  â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  Time-Series (InfluxDB/Prometheus): Why choose it?                      â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 1: Columnar, time-partitioned storage                        â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 2: Optimized for append-only time-stamped data               â”‚â”‚
â”‚  â”‚  â”œâ”€â”€ Level 3: Horizontal scaling, retention policies                    â”‚â”‚
â”‚  â”‚  â””â”€â”€ Level 4: Metrics â†’ alerting â†’ dashboards pipeline                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  THIS IS THE "SYSTEM DESIGN INTERVIEW" LEVEL:                               â”‚
â”‚  â€¢ "What database would you use for X?" - Answer with trade-offs           â”‚
â”‚  â€¢ "Why not use MongoDB?" - Explain CAP/PACELC implications                â”‚
â”‚  â€¢ "How would you scale this?" - Combine sharding + caching + queuing      â”‚
â”‚                                                                              â”‚
â”‚  APPLIES TO:                                                                â”‚
â”‚  âœ… Every system design question!                                           â”‚
â”‚  âœ… This is where you demonstrate senior-level thinking                     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Table of Contents
1. [Database Types Overview](#1-database-types-overview)
2. [PostgreSQL/MySQL (Relational)](#2-postgresqlmysql-relational)
3. [Cassandra (Wide-Column)](#3-cassandra-wide-column)
4. [Redis (Key-Value & Caching)](#4-redis-key-value--caching)
5. [Kafka (Message Streaming)](#5-kafka-message-streaming)
6. [Time-Series Databases](#6-time-series-databases)
7. [OLTP vs OLAP](#7-oltp-vs-olap)
8. [Blob/Object Storage](#8-blobobject-storage)
9. [Decision Matrix](#9-decision-matrix)

---

## 1. Database Types Overview

> Quick reference for database types. Detailed deep dives are in dedicated sections below.

### The Database Landscape

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE TYPES BY DATA MODEL                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚                    SQL (Relational)                                â”‚   â”‚
â”‚  â”‚                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚   â”‚
â”‚  â”‚                           â”‚                                         â”‚   â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚   â”‚
â”‚  â”‚         â”‚                 â”‚                 â”‚                      â”‚   â”‚
â”‚  â”‚         â–¼                 â–¼                 â–¼                      â”‚   â”‚
â”‚  â”‚    PostgreSQL          MySQL           Oracle                      â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚                    NoSQL (Non-Relational)                          â”‚   â”‚
â”‚  â”‚                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚   â”‚
â”‚  â”‚                           â”‚                                         â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚    â”‚          â”‚           â”‚           â”‚            â”‚               â”‚   â”‚
â”‚  â”‚    â–¼          â–¼           â–¼           â–¼            â–¼               â”‚   â”‚
â”‚  â”‚ Key-Value  Document  Wide-Column   Graph     Time-Series          â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Redis     MongoDB    Cassandra    Neo4j      InfluxDB            â”‚   â”‚
â”‚  â”‚  DynamoDB  Couchbase  HBase        Neptune    TimescaleDB         â”‚   â”‚
â”‚  â”‚  Memcached            Bigtable                Prometheus          â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚                    Specialized                                     â”‚   â”‚
â”‚  â”‚                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚   â”‚
â”‚  â”‚                           â”‚                                         â”‚   â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚   â”‚
â”‚  â”‚         â”‚                 â”‚                 â”‚                      â”‚   â”‚
â”‚  â”‚         â–¼                 â–¼                 â–¼                      â”‚   â”‚
â”‚  â”‚     Search           Message Queue       NewSQL                   â”‚   â”‚
â”‚  â”‚   Elasticsearch        Kafka          CockroachDB                 â”‚   â”‚
â”‚  â”‚   Solr                 RabbitMQ       Spanner                     â”‚   â”‚
â”‚  â”‚   Algolia              Kinesis        YugabyteDB                  â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Types Comparison

| Type | Examples | Data Model | Best For | Not For |
|------|----------|------------|----------|---------|
| **Relational (SQL)** | PostgreSQL, MySQL, Oracle | Tables with rows & columns, relationships via JOINs | Complex queries, ACID transactions, data integrity, JOINs | Unstructured data, horizontal scaling, schema changes |
| **Key-Value** | Redis, DynamoDB, Memcached | Simple key â†’ value pairs | Caching, sessions, simple lookups, counters | Complex queries, relationships, range scans |
| **Document** | MongoDB, Couchbase, Firestore | JSON-like documents, nested data | Flexible schema, content management, catalogs | Heavy JOINs, strict schema enforcement |
| **Wide-Column** | Cassandra, HBase, Bigtable | Rows with dynamic columns, column families | Time-series, write-heavy, IoT, logs, analytics | Ad-hoc queries, JOINs, strong consistency |
| **Graph** | Neo4j, Amazon Neptune, ArangoDB | Nodes and edges (relationships) | Social networks, recommendations, fraud detection | Simple CRUD, tabular data, analytics |
| **Time-Series** | InfluxDB, TimescaleDB, Prometheus | Timestamped data points | Metrics, monitoring, IoT, financial data | General purpose, relationships |
| **Search** | Elasticsearch, Solr, Algolia | Inverted index for full-text search | Full-text search, log analytics, autocomplete | Primary data store, transactions |
| **NewSQL** | CockroachDB, Spanner, TiDB | Relational + distributed | SQL + horizontal scale, global distribution | Simple apps (overkill), cost-sensitive |

### When to Use What: Decision Flowchart

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHOOSING A DATABASE TYPE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  START: What's your PRIMARY access pattern?                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  Need complex JOINs and ACID transactions?                                 â”‚
â”‚  â”œâ”€â”€ YES â†’ Relational (PostgreSQL, MySQL)                                  â”‚
â”‚  â”‚         â””â”€â”€ Need global scale? â†’ NewSQL (CockroachDB, Spanner)          â”‚
â”‚  â”‚                                                                          â”‚
â”‚  â””â”€â”€ NO â†’ What's your data structure?                                      â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â”œâ”€â”€ Simple key â†’ value lookups?                                  â”‚
â”‚           â”‚   â””â”€â”€ Key-Value (Redis for cache, DynamoDB for persistence)   â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â”œâ”€â”€ Nested/hierarchical documents?                               â”‚
â”‚           â”‚   â””â”€â”€ Document (MongoDB, Couchbase)                            â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â”œâ”€â”€ Time-stamped events/metrics?                                 â”‚
â”‚           â”‚   â””â”€â”€ Wide-Column (Cassandra) or Time-Series (InfluxDB)       â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â”œâ”€â”€ Complex relationships to traverse?                           â”‚
â”‚           â”‚   â””â”€â”€ Graph (Neo4j, Neptune)                                   â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â””â”€â”€ Full-text search needed?                                     â”‚
â”‚               â””â”€â”€ Search (Elasticsearch) + another DB as primary          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> ğŸ‘‰ **Deep dives for Key-Value (Redis), Wide-Column (Cassandra), and Time-Series are in dedicated sections below.**
> 
> Document (MongoDB) and Graph (Neo4j) databases are less common in system design interviews but useful for specific use cases like content management and social networks respectively.

### Common Multi-Database Architectures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    POLYGLOT PERSISTENCE                                      â”‚
â”‚         "Use the right database for each use case"                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  EXAMPLE: E-Commerce Platform                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚                         Application                                â”‚   â”‚
â”‚  â”‚                             â”‚                                       â”‚   â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚     â”‚           â”‚           â”‚           â”‚           â”‚              â”‚   â”‚
â”‚  â”‚     â–¼           â–¼           â–¼           â–¼           â–¼              â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  PostgreSQL   Redis     Elasticsearch  Cassandra   S3             â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€             â”‚   â”‚
â”‚  â”‚  Users        Sessions  Product        Event       Product        â”‚   â”‚
â”‚  â”‚  Orders       Cart      Search         Logs        Images         â”‚   â”‚
â”‚  â”‚  Payments     Cache                    Analytics                  â”‚   â”‚
â”‚  â”‚  (ACID!)      (Fast!)   (Search!)     (Scale!)    (Files!)       â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  WHY MULTIPLE DATABASES?                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ PostgreSQL: ACID for money-related operations                           â”‚
â”‚  â€¢ Redis: Sub-millisecond cache, session storage                          â”‚
â”‚  â€¢ Elasticsearch: Full-text search, autocomplete                          â”‚
â”‚  â€¢ Cassandra: High-volume event logging, no JOINs needed                  â”‚
â”‚  â€¢ S3: Cheap storage for large files                                      â”‚
â”‚                                                                              â”‚
â”‚  KEPT IN SYNC VIA:                                                          â”‚
â”‚  â€¢ CDC (Debezium) for PostgreSQL â†’ Kafka â†’ Elasticsearch                  â”‚
â”‚  â€¢ Application-level writes to multiple stores                            â”‚
â”‚  â€¢ Event-driven architecture                                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. PostgreSQL/MySQL (Relational)

### Core Identity

| Aspect | PostgreSQL | MySQL |
|--------|------------|-------|
| **Architecture** | Process-per-connection | Thread-per-connection |
| **MVCC** | Heap-based (needs VACUUM) | Undo log-based |
| **Replication** | Streaming (WAL) | Binary log |
| **JSON Support** | Native JSONB | JSON type |
| **Best For** | Complex queries, data integrity | High read throughput |

### CAP/PACELC Classification

```
SINGLE NODE: CA (no partition tolerance)
WITH SYNC REPLICATION: CP / PC/EC
  - During partition: Writes blocked (Consistency over Availability)
  - Normal operation: Consistent, higher latency (wait for replica ACK)

WITH ASYNC REPLICATION: AP / PA/EL  
  - During partition: Writes continue on primary
  - Normal operation: Fast, eventual consistency
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Financial transactions (ACID guarantees)
â”œâ”€â”€ E-commerce orders (complex relations, consistency)
â”œâ”€â”€ User accounts & authentication
â”œâ”€â”€ Content management (rich queries)
â”œâ”€â”€ Read-heavy workloads (B-Tree = fast point lookups & range scans)
â”‚   â†’ B-Tree: O(log n) reads, data is sorted, sequential I/O for ranges
â”‚   â†’ Index-organized: clustered index keeps related data together
â””â”€â”€ Any system where consistency > availability

âš ï¸ LIMITATIONS:
â”œâ”€â”€ Single-node write throughput ceiling (~10K-50K TPS)
â”‚   â†’ B-Tree: Writes require in-place updates, random I/O
â”‚   â†’ Every write may trigger page splits, rebalancing
â”œâ”€â”€ Scaling reads: Add replicas
â”œâ”€â”€ Scaling writes: Vertical only (or application-level sharding)
â””â”€â”€ Not ideal for: Time-series, IoT, massive write loads (use LSM-Tree DBs)
```

### Interview Talking Points

```
"We use PostgreSQL for our user and order data because:
1. ACID transactions ensure money never disappears
2. Foreign keys maintain referential integrity
3. Complex JOIN queries for reporting
4. JSONB for flexible attributes without schema changes

For scaling, we use:
- Read replicas for query distribution
- Connection pooling (PgBouncer) for efficiency
  â€¢ Connection pooling = reuse DB connections instead of opening/closing per request
  â€¢ PgBouncer = popular connection pooler (sits between app and DB)
  â€¢ Essential for: microservices, serverless, high-concurrency apps
- Application-level sharding by tenant_id if needed"
```

---

## 3. Cassandra (Wide-Column)

### Core Identity

| Aspect | Details |
|--------|---------|
| **Data Model** | Wide-column (partition key + clustering columns) |
| **Storage** | LSM-Tree (write-optimized) |
| **Consistency** | Tunable (ONE to ALL) |
| **Replication** | Peer-to-peer, no single leader |
| **Query Language** | CQL (SQL-like, but limited) |

### Why "Wide-Column"?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WIDE-COLUMN EXPLAINED                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  RELATIONAL (Fixed Schema):                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Every row MUST have the same columns:                                      â”‚
â”‚                                                                              â”‚
â”‚  | user_id | name  | email           | phone       |                       â”‚
â”‚  |---------|-------|-----------------|-------------|                       â”‚
â”‚  | 1       | Alice | alice@mail.com  | 555-1234    |                       â”‚
â”‚  | 2       | Bob   | bob@mail.com    | 555-5678    |                       â”‚
â”‚  | 3       | Carol | carol@mail.com  | NULL        | â† Must have column!   â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚                                                                              â”‚
â”‚  WIDE-COLUMN (Dynamic Columns):                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Each row can have DIFFERENT columns, and MANY of them (thousands!):       â”‚
â”‚                                                                              â”‚
â”‚  Row Key: "user:1"                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ name:Alice â”‚ email:alice@mail.com â”‚ phone:555-1234 â”‚ age:30 â”‚ ...  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Row Key: "user:2"                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ name:Bob â”‚ email:bob@mail.com â”‚ twitter:@bob â”‚           â”‚ â† Different! â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                              â”‚
â”‚  Row Key: "sensor:001:2024-01-15"                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 00:00:temp:72 â”‚ 00:00:humid:45 â”‚ 00:01:temp:73 â”‚ 00:01:humid:46 â”‚...â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â†‘ This row could have THOUSANDS of columns (one per timestamp)!           â”‚
â”‚                                                                              â”‚
â”‚  WHY "WIDE"?                                                                â”‚
â”‚  â€¢ Rows can grow "wide" with many columns                                  â”‚
â”‚  â€¢ Columns are dynamic (add new ones anytime, no ALTER TABLE)              â”‚
â”‚  â€¢ Think of it as: row_key â†’ { column_name: value, column_name: value }    â”‚
â”‚  â€¢ Essentially a 2D key-value store                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CAP/PACELC Classification

```
CAP: AP (Available during Partition)
PACELC: PA/EL (Prioritize Availability and Low Latency)

Default consistency: LOCAL_ONE (fast but weak)
Can tune per-query: QUORUM, ALL (stronger but slower)

Trade-off knobs:
- Replication Factor: 3 (typical)
- Write Consistency: QUORUM = 2/3 must ACK
- Read Consistency: QUORUM = 2/3 must respond
- For strong consistency: R + W > N
```

### Data Model Design

```
CASSANDRA DESIGN PRINCIPLE: Model for your queries, not your entities

âŒ WRONG (relational thinking):
  users(id, name, email)
  orders(id, user_id, product, time)
  
  SELECT * FROM orders WHERE user_id = 123 ORDER BY time DESC
  â†’ Requires secondary index, SLOW

âœ… RIGHT (query-driven):
  orders_by_user(user_id, time, order_id, product)
  PRIMARY KEY ((user_id), time)
  
  â†’ user_id is partition key (data locality)
  â†’ time is clustering column (sorted within partition)
  â†’ Query is a single partition scan, FAST
```

### Primary Key = Partition Key + Clustering Key

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“– DETAILED COVERAGE: See Level 2 - Database Logic                        â”‚
â”‚     Section: "NoSQL Indexing: Partition Key, Clustering Key & Secondary    â”‚
â”‚              Indexes"                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  QUICK REFERENCE:                                                            â”‚
â”‚                                                                              â”‚
â”‚  PRIMARY KEY ((partition_key), clustering_key1, clustering_key2, ...)       â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                      â”‚                            â”‚                          â”‚
â”‚            PARTITION KEY                  CLUSTERING COLUMNS                 â”‚
â”‚         (WHERE data lives)              (HOW data is sorted)                â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚     PARTITION KEY       â”‚         CLUSTERING KEY                     â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Determines WHICH NODE   â”‚ Determines SORT ORDER within partition     â”‚  â”‚
â”‚  â”‚ MUST be in WHERE (=)    â”‚ Optional, enables range queries (<, >)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  EXAMPLE:                                                                    â”‚
â”‚  CREATE TABLE messages (                                                     â”‚
â”‚      chat_id UUID,                                                           â”‚
â”‚      sent_at TIMESTAMP,                                                      â”‚
â”‚      content TEXT,                                                           â”‚
â”‚      PRIMARY KEY ((chat_id), sent_at)  â† chat_id: partition, sent_at: sort  â”‚
â”‚  );                                                                          â”‚
â”‚                                                                              â”‚
â”‚  âœ… FAST: WHERE chat_id = 'abc' AND sent_at > '2024-01-15'                  â”‚
â”‚  âŒ SLOW: WHERE sent_at > '2024-01-15' (no partition key = cluster scan!)   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DynamoDB Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DYNAMODB: KEY-VALUE vs WIDE-COLUMN                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  DynamoDB supports TWO modes:                                               â”‚
â”‚                                                                              â”‚
â”‚  1. PURE KEY-VALUE (simple):                                                â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚     Only partition key, no sort key. Like Redis.                           â”‚
â”‚                                                                              â”‚
â”‚     Key: "user:123" â†’ Value: {name: "Alice", email: "alice@..."}           â”‚
â”‚     Key: "session:abc" â†’ Value: {userId: 123, expires: "..."}              â”‚
â”‚                                                                              â”‚
â”‚     âœ… Simple lookups: GetItem("user:123")                                  â”‚
â”‚     âŒ No range queries (no sort key)                                       â”‚
â”‚                                                                              â”‚
â”‚  2. WIDE-COLUMN (with sort key):                                            â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚     Partition key + sort key. Like Cassandra.                              â”‚
â”‚                                                                              â”‚
â”‚     Partition: "user:123"                                                   â”‚
â”‚     â”œâ”€â”€ Sort: "order#2024-01-15" â†’ {total: 99.99, items: [...]}            â”‚
â”‚     â”œâ”€â”€ Sort: "order#2024-01-20" â†’ {total: 149.50, status: "shipped"}      â”‚
â”‚     â””â”€â”€ Sort: "profile"          â†’ {name: "Alice", tier: "gold"}           â”‚
â”‚                                                                              â”‚
â”‚     âœ… Range queries on sort key                                            â”‚
â”‚     âœ… Multiple item types in same partition (single-table design)         â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚                                                                              â”‚
â”‚  DynamoDB is often called "key-value" but with sort key it's wide-column.  â”‚
â”‚  Similar concepts to Cassandra, different terminology:                      â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚     Cassandra      â”‚      DynamoDB      â”‚      Meaning       â”‚          â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚
â”‚  â”‚   Partition Key    â”‚   Partition Key    â”‚ Where data lives   â”‚          â”‚
â”‚  â”‚   Clustering Key   â”‚    Sort Key        â”‚ Order within       â”‚          â”‚
â”‚  â”‚   Primary Key      â”‚   Composite Key    â”‚ PK + SK together   â”‚          â”‚
â”‚  â”‚   Secondary Index  â”‚   LSI / GSI        â”‚ Query on non-keys  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                              â”‚
â”‚  EXAMPLE: Orders Table                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  Table: orders                                                              â”‚
â”‚  Partition Key: customer_id                                                 â”‚
â”‚  Sort Key: order_date                                                       â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ customer_id(PK) â”‚ order_date(SK)  â”‚ Attributes (flexible schema)     â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ user_123        â”‚ 2024-01-15      â”‚ {total: 99.99, items: [...]}     â”‚  â”‚
â”‚  â”‚ user_123        â”‚ 2024-01-20      â”‚ {total: 149.50, status: "shipped"}â”‚  â”‚
â”‚  â”‚ user_456        â”‚ 2024-01-18      â”‚ {total: 25.00, items: [...]}     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  QUERIES:                                                                   â”‚
â”‚  âœ… FAST: Get all orders for user_123                                      â”‚
â”‚           â†’ Single partition, sorted by date                               â”‚
â”‚  âœ… FAST: Get user_123's orders between Jan 10-20                          â”‚
â”‚           â†’ Partition + sort key range query                               â”‚
â”‚  âŒ SLOW: Get all orders with total > $100                                 â”‚
â”‚           â†’ Requires scan or GSI on 'total'                                â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ‘‰ For full coverage of LSI vs GSI trade-offs, see Level 2 - Database Logic.
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Time-series data (IoT sensors, metrics)
â”œâ”€â”€ Event logging (append-only, massive scale)
â”œâ”€â”€ Messaging (inbox per user)
â”œâ”€â”€ Recommendations (pre-computed per user)
â”œâ”€â”€ Write-heavy workloads (LSM-Tree = blazing fast writes)
â”‚   â†’ LSM-Tree: Writes go to memtable (RAM), sequential disk flush
â”‚   â†’ No random I/O on writes, no page splits
â”‚   â†’ Can handle 100K+ writes/sec per node
â””â”€â”€ Any write-heavy, read-by-key workload

âš ï¸ LIMITATIONS:
â”œâ”€â”€ No JOINs (denormalize everything)
â”œâ”€â”€ No ad-hoc queries (design tables per query)
â”œâ”€â”€ Deletes are expensive (tombstones)
â”œâ”€â”€ Secondary indexes are limited
â”œâ”€â”€ Reads can be slower (LSM-Tree may check multiple SSTables)
â”‚   â†’ Point reads: check memtable + multiple SSTable levels
â”‚   â†’ Mitigated by bloom filters, but still slower than B-Tree
â””â”€â”€ Not for: Complex queries, small datasets, strong consistency
```

### Interview Talking Points

```
"We use Cassandra for our event logging because:
1. 100K+ writes/sec across the cluster
2. Time-series data is append-only (LSM-Tree sweet spot)
3. Partition by (device_id, day) for data locality
4. Cluster by timestamp for efficient range queries
5. Tunable consistency: ONE for writes, QUORUM for reads

We accept eventual consistency because:
- Logs don't need strong consistency
- We can tolerate seconds of lag
- Availability is more important than perfect ordering"
```

---

## 4. Redis (Key-Value & Caching)

### Core Identity

| Aspect | Details |
|--------|---------|
| **Storage** | In-memory (with optional persistence) |
| **Data Structures** | Strings, Lists, Sets, Hashes, Sorted Sets, Streams |
| **Latency** | Sub-millisecond |
| **Persistence** | RDB (snapshots) / AOF (append-only log) |
| **Clustering** | Redis Cluster (hash slots) |

### CAP/PACELC Classification

```
CAP: AP (in cluster mode, prioritizes availability)
PACELC: PA/EL (fast and available)

Replication: Asynchronous
- Primary failure can lose recent writes
- For durability: Use WAIT command or accept loss

Cluster mode:
- 16384 hash slots distributed across nodes
- Client routes to correct node
- Failover via Sentinel or Cluster consensus
```

### Scaling Redis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HOW TO SCALE REDIS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. VERTICAL SCALING (Scale Up)                                             â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚     â€¢ Add more RAM (Redis is memory-bound)                                 â”‚
â”‚     â€¢ Faster CPU helps with high ops/sec                                   â”‚
â”‚     â€¢ Limit: Single machine capacity                                       â”‚
â”‚                                                                              â”‚
â”‚  2. READ REPLICAS (Scale Reads)                                             â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚     â”‚   Primary   â”‚â”€â”€â”€â”€â”€â–ºâ”‚  Replica 1  â”‚ â† Reads                           â”‚
â”‚     â”‚  (Writes)   â”‚â”€â”€â”€â”€â”€â–ºâ”‚  Replica 2  â”‚ â† Reads                           â”‚
â”‚     â”‚             â”‚â”€â”€â”€â”€â”€â–ºâ”‚  Replica 3  â”‚ â† Reads                           â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                                              â”‚
â”‚     â€¢ Primary handles all writes                                           â”‚
â”‚     â€¢ Replicas handle read traffic                                         â”‚
â”‚     â€¢ Async replication (eventual consistency)                             â”‚
â”‚                                                                              â”‚
â”‚  3. REDIS CLUSTER (Scale Writes + Data)                                     â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚                    16384 Hash Slots                               â”‚   â”‚
â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚     â”‚  â”‚  Node A     â”‚  â”‚  Node B     â”‚  â”‚  Node C     â”‚              â”‚   â”‚
â”‚     â”‚  â”‚ Slots 0-5460â”‚  â”‚Slots 5461-  â”‚  â”‚Slots 10923- â”‚              â”‚   â”‚
â”‚     â”‚  â”‚             â”‚  â”‚   10922     â”‚  â”‚   16383     â”‚              â”‚   â”‚
â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚     â€¢ Data automatically sharded by key: slot = CRC16(key) % 16384         â”‚
â”‚     â€¢ Each node handles a subset of keys (horizontal scaling)              â”‚
â”‚     â€¢ Add more nodes â†’ more capacity                                       â”‚
â”‚     â€¢ Client-side routing or proxy (Redis Cluster protocol)                â”‚
â”‚                                                                              â”‚
â”‚  4. REDIS SENTINEL (High Availability, not scaling)                        â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚     â€¢ Monitors primary, auto-promotes replica on failure                   â”‚
â”‚     â€¢ Not for scaling, just for failover                                   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Caching Patterns

| Pattern | One-Liner Definition |
|---------|----------------------|
| **Cache-Aside** | App checks cache first; on miss, fetches from DB and populates cache |
| **Write-Through** | App writes to DB and cache simultaneously (cache always up-to-date) |
| **Write-Behind** | App writes to cache only; cache asynchronously writes to DB (faster, riskier) |
| **Read-Through** | Cache itself fetches from DB on miss (app only talks to cache) |

### Key Patterns

```
1. CACHE-ASIDE (Lazy Loading)
   â†’ App checks cache first; on miss, fetches from DB and populates cache
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ read(key):                                  â”‚
   â”‚   value = redis.get(key)                    â”‚
   â”‚   if value is None:                         â”‚
   â”‚       value = db.query(key)                 â”‚
   â”‚       redis.setex(key, TTL, value)          â”‚
   â”‚   return value                              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   âœ… Only caches what's needed
   âŒ First request always misses (cold cache)

2. WRITE-THROUGH
   â†’ App writes to DB and cache simultaneously
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ write(key, value):                          â”‚
   â”‚   db.insert(key, value)                     â”‚
   â”‚   redis.set(key, value)                     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   âœ… Cache always up-to-date
   âŒ Write latency increases (two writes)
   âŒ May cache data that's never read

3. RATE LIMITING (Sliding Window)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ZADD rate:{ip} {timestamp} {request_id}     â”‚
   â”‚ ZREMRANGEBYSCORE rate:{ip} 0 {timestamp-60} â”‚
   â”‚ ZCARD rate:{ip} â†’ count in last 60 seconds  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. DISTRIBUTED LOCK (Redlock)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ SET lock:{resource} {token} NX PX 30000     â”‚
   â”‚ # NX = only if not exists                   â”‚
   â”‚ # PX = expire in 30 seconds                 â”‚
   â”‚ # token = unique identifier for unlock      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5. LEADERBOARD (Sorted Set)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ZADD leaderboard {score} {user_id}          â”‚
   â”‚ ZREVRANGE leaderboard 0 9 WITHSCORES        â”‚
   â”‚ â†’ Top 10 users by score, O(log N) updates   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Caching (session, query results, computed data)
â”œâ”€â”€ Rate limiting
â”œâ”€â”€ Leaderboards / rankings
â”œâ”€â”€ Real-time analytics counters
â”œâ”€â”€ Pub/Sub messaging
â”œâ”€â”€ Distributed locks
â””â”€â”€ Queue (with Redis Streams)

âš ï¸ LIMITATIONS:
â”œâ”€â”€ Data must fit in memory (expensive at scale)
â”œâ”€â”€ Persistence options have trade-offs
â”œâ”€â”€ Not a primary data store
â”œâ”€â”€ Cluster adds complexity
â””â”€â”€ Not for: Large datasets, durable storage, complex queries
```

### Interview Talking Points

```
"We use Redis as our caching layer because:
1. Sub-millisecond latency for hot data
2. Reduces database load by 90%+
3. Native data structures (sorted sets for leaderboards)
4. TTL-based expiration for cache freshness

Cache invalidation strategy:
- CDC events trigger cache deletes
- TTL as a safety net
- Cache-aside for reads

For distributed locks:
- Redlock algorithm across 5 Redis instances
- Fencing tokens for safety"
```

---

## 5. Kafka (Message Streaming)

### Core Identity

| Aspect | Details |
|--------|---------|
| **Model** | Distributed commit log |
| **Storage** | Append-only log on disk |
| **Ordering** | Per-partition ordering guaranteed |
| **Retention** | Time-based or size-based |
| **Consumers** | Pull-based with consumer groups |

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         KAFKA CLUSTER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  TOPIC: orders (3 partitions, replication factor 2)                 â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Partition 0 â”‚  â”‚ Partition 1 â”‚  â”‚ Partition 2 â”‚                 â”‚
â”‚  â”‚ Leader: B1  â”‚  â”‚ Leader: B2  â”‚  â”‚ Leader: B3  â”‚                 â”‚
â”‚  â”‚ Replica: B2 â”‚  â”‚ Replica: B3 â”‚  â”‚ Replica: B1 â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                      â”‚
â”‚  LEADER vs REPLICA:                                                  â”‚
â”‚  â€¢ Leader: The broker that handles ALL reads/writes for a partition â”‚
â”‚  â€¢ Replica: Passive copy for fault tolerance (syncs from leader)    â”‚
â”‚  â€¢ If leader fails â†’ a replica is promoted to new leader            â”‚
â”‚  â€¢ Producers/consumers only talk to the leader (by default)         â”‚
â”‚  â€¢ Replication factor 2 = 1 leader + 1 replica (survives 1 failure)                 â”‚
â”‚        â”‚                â”‚                â”‚                          â”‚
â”‚        â–¼                â–¼                â–¼                          â”‚
â”‚  [msg1,msg4,...]  [msg2,msg5,...]  [msg3,msg6,...]                  â”‚
â”‚                                                                      â”‚
â”‚  HOW PRODUCER DECIDES WHICH PARTITION TO SEND TO:                    â”‚
â”‚  â€¢ No key provided: Round-robin (distribute evenly across partitions)â”‚
â”‚    Message 1 â†’ Partition 0                                           â”‚
â”‚    Message 2 â†’ Partition 1                                           â”‚
â”‚    Message 3 â†’ Partition 2                                           â”‚
â”‚    Message 4 â†’ Partition 0 (cycles back)                             â”‚
â”‚    â†’ Good for load balancing, but no ordering guarantee              â”‚
â”‚                                                                      â”‚
â”‚  PARTITIONING:                                                       â”‚
â”‚  â€¢ Default (no key): Round-robin (load balanced, no ordering)        â”‚
â”‚  â€¢ With key: hash(key) % partitions (same key â†’ same partition)      â”‚
â”‚                                                                      â”‚
â”‚  ORDERING GUARANTEE:                                                 â”‚
â”‚  â€¢ Within a partition: GUARANTEED (append-only log, like WAL)        â”‚
â”‚    â†’ Messages appended to end, never inserted in middle              â”‚
â”‚    â†’ Consumer reads in exact order producer wrote                    â”‚
â”‚  â€¢ Across partitions: NO guarantee                                   â”‚
â”‚    â†’ That's why you use a key when order matters!                    â”‚
â”‚                                                                      â”‚
â”‚  SUMMARY:                                                            â”‚
â”‚  â€¢ Default (no key): Round-robin                                             â”‚
â”‚  â€¢ With key: hash(key) % num_partitions                             â”‚
â”‚  â€¢ Messages with same key â†’ same partition â†’ ordering guaranteed    â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Consumer Groups

```
CONSUMER GROUP: order-processors

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                      â”‚
â”‚  Partition 0 â”€â”€â”€â”€â”€â”€â–º Consumer A                                     â”‚
â”‚  Partition 1 â”€â”€â”€â”€â”€â”€â–º Consumer B                                     â”‚
â”‚  Partition 2 â”€â”€â”€â”€â”€â”€â–º Consumer C                                     â”‚
â”‚                                                                      â”‚
â”‚  â€¢ Each partition assigned to ONE consumer in a group               â”‚
â”‚  â€¢ Add consumers (up to partition count) for parallelism            â”‚
â”‚  â€¢ Consumer failure â†’ partition reassigned to another               â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MULTIPLE GROUPS (Fan-out):

Topic: orders
â”œâ”€â”€ Consumer Group: analytics-pipeline
â”‚   â””â”€â”€ Reads all messages for analytics
â”œâ”€â”€ Consumer Group: notification-service  
â”‚   â””â”€â”€ Reads all messages for emails
â””â”€â”€ Consumer Group: inventory-service
    â””â”€â”€ Reads all messages to update stock
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Event sourcing (immutable event log)
â”œâ”€â”€ Stream processing (real-time pipelines)
â”œâ”€â”€ Microservices communication (decoupling)
â”œâ”€â”€ Log aggregation
â”œâ”€â”€ CDC destination (from Debezium)
â””â”€â”€ Message replay (re-process historical events)

âš ï¸ LIMITATIONS:
â”œâ”€â”€ Not a database (no queries, only sequential read)
â”œâ”€â”€ Not for request-response (use HTTP)
â”œâ”€â”€ Ordering only within partition
â”œâ”€â”€ Operational complexity (Zookeeper/KRaft, brokers)
â””â”€â”€ Latency higher than direct calls
```

### Interview Talking Points

```
"We use Kafka as the backbone of our event-driven architecture:

1. Decoupling: Services publish events, don't know consumers
2. Durability: Events stored for 7 days, replay if needed
3. Scaling: Add partitions for throughput, consumers for parallelism
4. Ordering: Partition by user_id so user events processed in order

Key patterns:
- Outbox pattern: Write to DB + outbox, Debezium â†’ Kafka
- Saga orchestration: Kafka connects saga steps
- CQRS: Commands via HTTP, events via Kafka to read model"
```

---

## 6. Time-Series Databases

> Optimized for timestamped data points - essential for monitoring, IoT, and analytics.

### Core Identity

| Aspect | Details |
|--------|---------|
| **Data Model** | Metric name + tags + timestamp + value |
| **Storage** | Columnar, time-partitioned, compressed |
| **Queries** | Time-range based aggregations |
| **Retention** | Automatic downsampling and expiration |
| **Ingestion** | High-throughput writes, append-only |

> **ğŸ’¡ Columnar Storage: Same as OLAP?**
> 
> **Similar concept** - both store data by columns (not rows) for better compression and aggregation performance.
> 
> | Aspect | OLAP Columnar (Snowflake, Redshift) | Time-Series (InfluxDB, Prometheus) |
> |--------|-------------------------------------|-------------------------------------|
> | **Optimized for** | Ad-hoc analytics across many dimensions | Time-based queries on metrics |
> | **Partitioning** | By various keys | By time (automatic) |
> | **Special features** | Complex JOINs, SQL | Downsampling, retention, rate(), derivative() |
> | **Compression** | General columnar | Time-specific (delta, gorilla encoding) |
> | **Ingestion** | Batch-oriented | High-frequency streaming |
> 
> **ClickHouse** blurs this line - it's an OLAP columnar DB that's also excellent for time-series!

### CAP/PACELC Classification

```
CAP: AP (typically, prioritize availability for metrics)
PACELC: PA/EL (fast writes, eventual consistency acceptable)

Most time-series DBs prioritize:
- High write throughput (millions of points/sec)
- Fast time-range queries
- Automatic data lifecycle management
```

### Data Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIME-SERIES DATA MODEL                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  METRIC + TAGS + TIMESTAMP + VALUE                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  cpu_usage{host="server-01", region="us-east"} @ 2024-01-15T10:00:00 = 45.2â”‚
â”‚  cpu_usage{host="server-01", region="us-east"} @ 2024-01-15T10:00:01 = 47.8â”‚
â”‚  cpu_usage{host="server-02", region="eu-west"} @ 2024-01-15T10:00:00 = 32.1â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  COMPONENTS:                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Metric Name   â”‚ What you're measuring (cpu_usage, temperature, etc.) â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Tags/Labels   â”‚ Dimensions to filter by (host, region, service)      â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Timestamp     â”‚ When the measurement occurred                        â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Value         â”‚ The measurement (usually numeric)                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIME-SERIES SPECIFIC FEATURES                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. AUTOMATIC DOWNSAMPLING                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  Raw data (1-second intervals):                                             â”‚
â”‚  10:00:00 â†’ 45.2                                                            â”‚
â”‚  10:00:01 â†’ 47.8                                                            â”‚
â”‚  10:00:02 â†’ 43.1                                                            â”‚
â”‚  ...                                                                         â”‚
â”‚                                                                              â”‚
â”‚  After 7 days â†’ Downsample to 1-minute averages:                           â”‚
â”‚  10:00:00 â†’ 45.4 (avg of 60 points)                                        â”‚
â”‚  10:01:00 â†’ 46.2                                                            â”‚
â”‚                                                                              â”‚
â”‚  After 30 days â†’ Downsample to 1-hour averages:                            â”‚
â”‚  10:00:00 â†’ 45.8 (avg of 60 minutes)                                       â”‚
â”‚                                                                              â”‚
â”‚  BENEFIT: Keep years of data without exploding storage                     â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  2. RETENTION POLICIES                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Raw data: Keep 7 days, then delete                                      â”‚
â”‚  â€¢ 1-minute rollups: Keep 30 days                                          â”‚
â”‚  â€¢ 1-hour rollups: Keep 1 year                                             â”‚
â”‚  â€¢ Daily rollups: Keep forever                                             â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  3. TIME-BASED QUERIES                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  "Last 5 minutes":  WHERE time > now() - 5m                                â”‚
â”‚  "Today vs yesterday": Compare same hour, different day                    â”‚
â”‚  "90th percentile over 1 hour windows"                                     â”‚
â”‚  "Rate of change (derivative)"                                             â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ideal Use Cases

```
âœ… PERFECT FOR:
â”œâ”€â”€ Application metrics (latency, error rates, throughput)
â”œâ”€â”€ Infrastructure monitoring (CPU, memory, disk, network)
â”œâ”€â”€ IoT sensor data (temperature, humidity, location)
â”œâ”€â”€ Financial market data (stock prices, trades)
â”œâ”€â”€ User analytics (DAU, session length, events over time)
â””â”€â”€ Log metrics (request rates, error counts)

âš ï¸ LIMITATIONS:
â”œâ”€â”€ Not for general-purpose queries (use a relational DB)
â”œâ”€â”€ Limited JOIN support
â”œâ”€â”€ High cardinality can be expensive
â”œâ”€â”€ Not ideal for: User data, transactions, relationships
```

### Why Are Time-Range Queries So Fast (Hot Question)?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HOW TIME-SERIES DBs ACHIEVE FAST QUERIES                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. TIME-BASED PARTITIONING (The Biggest Win!)                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  Data is automatically partitioned by time (hourly, daily chunks):          â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Query: "Show CPU usage for last 24 hours"                          â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Traditional DB:  Scan entire table â†’ Filter by timestamp â†’ SLOW    â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Time-Series DB:  Go directly to last 24 partitions â†’ FAST          â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  [2024-01-13] [2024-01-14] [2024-01-15] â† Only read these!          â”‚   â”‚
â”‚  â”‚       â†“             â†“             â†“                                  â”‚   â”‚
â”‚  â”‚   (skip)        (skip)        (read)                                 â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  2. DATA IS NATURALLY SORTED BY TIME                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Writes are append-only (always current timestamp)                        â”‚
â”‚  â€¢ No random inserts in the middle                                          â”‚
â”‚  â€¢ No need for B-tree index on timestamp - data IS the index!               â”‚
â”‚                                                                              â”‚
â”‚  3. COLUMNAR STORAGE + TIME-SPECIFIC COMPRESSION                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚  Technique     â”‚  How It Works  â”‚  Compression   â”‚                       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚  â”‚ Delta encoding â”‚ Store diff     â”‚ Timestamp:     â”‚                       â”‚
â”‚  â”‚                â”‚ between values â”‚ 1705312800000  â”‚                       â”‚
â”‚  â”‚                â”‚                â”‚ +1000 (+1 sec) â”‚                       â”‚
â”‚  â”‚                â”‚                â”‚ +1000          â”‚                       â”‚
â”‚  â”‚                â”‚                â”‚ (saves 90%!)   â”‚                       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚  â”‚ Gorilla/XOR    â”‚ For floats thatâ”‚ 45.2 â†’ 47.8    â”‚                       â”‚
â”‚  â”‚ encoding       â”‚ change slowly  â”‚ XOR diff tiny  â”‚                       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚  â”‚ Run-length     â”‚ Repeated valuesâ”‚ [0,0,0,0,0]    â”‚                       â”‚
â”‚  â”‚                â”‚ stored once    â”‚ â†’ (0, count:5) â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                              â”‚
â”‚  4. PRE-AGGREGATED ROLLUPS                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Raw data:      Every second (huge!)                                â”‚   â”‚
â”‚  â”‚  5-min rollup:  avg, min, max per 5 minutes                         â”‚   â”‚
â”‚  â”‚  1-hour rollup: avg, min, max per hour                              â”‚   â”‚
â”‚  â”‚  1-day rollup:  avg, min, max per day                               â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Query "last 6 months"?                                             â”‚   â”‚
â”‚  â”‚  â†’ Use 1-day rollup (180 rows) instead of raw (15M rows!)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  ğŸ’¡ Do you need to configure rollups?                                       â”‚
â”‚  â†’ YES, most TSDBs require one-time configuration (materialized views,    â”‚
â”‚    continuous aggregates, or recording rules). Some offer automatic       â”‚
â”‚    downsampling with retention policies.                                  â”‚
â”‚                                                                              â”‚
â”‚  âš ï¸  IMPORTANT: Retention vs Rollups - Two SEPARATE Concepts!              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  Q: "If I stored data in seconds, can I access it after 1 month?"          â”‚
â”‚  A: It depends on YOUR retention policy configuration!                      â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  RETENTION POLICY = How long to KEEP raw data before DELETING       â”‚   â”‚
â”‚  â”‚  ROLLUPS/DOWNSAMPLING = Creating ADDITIONAL aggregated versions     â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  These are INDEPENDENT! Raw data is NOT "converted" to rollups.    â”‚   â”‚
â”‚  â”‚  Raw data is either KEPT or DELETED based on retention.            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  TYPICAL CONFIGURATION (you decide!):                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Data Type          â”‚  Retention Period  â”‚  Storage Cost            â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  Raw (1-sec)        â”‚  7-30 days         â”‚  HUGE (delete after)     â”‚   â”‚
â”‚  â”‚  5-min rollups      â”‚  6 months          â”‚  Medium                  â”‚   â”‚
â”‚  â”‚  1-hour rollups     â”‚  2 years           â”‚  Small                   â”‚   â”‚
â”‚  â”‚  1-day rollups      â”‚  Forever           â”‚  Tiny                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  EXAMPLE SCENARIO:                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ You store CPU metrics every second                                       â”‚
â”‚  â€¢ Retention policy: raw data kept for 7 days                               â”‚
â”‚  â€¢ Rollup policy: 5-min avg kept for 1 year                                 â”‚
â”‚                                                                              â”‚
â”‚  Day 1:  Query "last hour" â†’ âœ… Second-level granularity available         â”‚
â”‚  Day 8:  Query "Day 1" â†’ âŒ Raw data DELETED, only 5-min rollup exists     â”‚
â”‚  Day 30: Query "Day 1" â†’ âŒ Only 5-min rollup (no second-level!)           â”‚
â”‚                                                                              â”‚
â”‚  ğŸ’¡ WANT TO KEEP SECOND-LEVEL FOREVER?                                      â”‚
â”‚  â€¢ Set retention = infinite (but storage cost will be MASSIVE!)            â”‚
â”‚  â€¢ Most companies don't need second-level data for historical analysis    â”‚
â”‚  â€¢ For debugging recent issues: 7-30 days of raw is usually enough        â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ğŸ’¡ WHERE IS ROLLUP DATA STORED?                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  â†’ Rollups are stored in SEPARATE tables/measurements/metrics              â”‚
â”‚  â†’ Raw data and rollup data are NOT mixed together                         â”‚
â”‚  â†’ Example: raw = cpu_usage, rollup = cpu_usage_5min, cpu_usage_hourly    â”‚
â”‚                                                                              â”‚
â”‚  QUERYING ROLLUPS:                                                          â”‚
â”‚  â€¢ EXPLICIT: You choose which to query (raw for recent, rollup for old)   â”‚
â”‚  â€¢ AUTOMATIC: Some TSDBs auto-select resolution based on time range       â”‚
â”‚                                                                              â”‚
â”‚                                                                              â”‚
â”‚  5. SEQUENTIAL I/O (Not Random!)                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  How time partitioning + columnar storage work TOGETHER:                    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 1: Partition by TIME (horizontal split)                       â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  [Partition: Jan 15] [Partition: Jan 16] [Partition: Jan 17]        â”‚   â”‚
â”‚  â”‚         â†“                   â†“                    â†“                   â”‚   â”‚
â”‚  â”‚    All metrics          All metrics          All metrics            â”‚   â”‚
â”‚  â”‚    for this day         for this day         for this day           â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Query "last 24 hours"? â†’ Only read Jan 17 partition!               â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚  STEP 2: Within each partition, COLUMNAR storage (vertical split)  â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Inside [Partition: Jan 17]:                                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚ timestamps  â”‚ cpu_usage   â”‚ memory_mb   â”‚ disk_io     â”‚          â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚   â”‚
â”‚  â”‚  â”‚ 10:00:00    â”‚ 45.2        â”‚ 8192        â”‚ 1024        â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ 10:00:01    â”‚ 47.8        â”‚ 8195        â”‚ 1028        â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ 10:00:02    â”‚ 46.1        â”‚ 8190        â”‚ 1030        â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ ...         â”‚ ...         â”‚ ...         â”‚ ...         â”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Stored as COLUMNS on disk (not rows!):                             â”‚   â”‚
â”‚  â”‚  [timestamps: 10:00:00, 10:00:01, 10:00:02, ...]  â† Sequential!     â”‚   â”‚
â”‚  â”‚  [cpu_usage:  45.2, 47.8, 46.1, ...]              â† Sequential!     â”‚   â”‚
â”‚  â”‚  [memory_mb:  8192, 8195, 8190, ...]              â† Sequential!     â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Query "AVG(cpu_usage)"? â†’ Read ONLY cpu_usage column sequentially  â”‚   â”‚
â”‚  â”‚  (Don't need to read memory_mb or disk_io at all!)                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  RESULT: Time partitioning (skip irrelevant days) +                        â”‚
â”‚          Columnar (read only needed columns) = BLAZING FAST                â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Time-Series DBs vs Cassandra for Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHY TIME-SERIES DBs OVER CASSANDRA?                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Cassandra CAN store time-series data (and many companies do!).            â”‚
â”‚  But purpose-built TSDBs have advantages:                                  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Feature            â”‚ Cassandra           â”‚ Time-Series DB (InfluxDB)   â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚ Auto Downsampling  â”‚ âŒ Build yourself    â”‚ âœ… Built-in (1sâ†’1mâ†’1h)      â”‚â”‚
â”‚  â”‚ Retention Policies â”‚ âŒ TTL creates       â”‚ âœ… Auto-delete old data     â”‚â”‚
â”‚  â”‚                    â”‚    tombstones!       â”‚    (no tombstones)          â”‚â”‚
â”‚  â”‚ Compression        â”‚ âš ï¸ Generic           â”‚ âœ… Specialized (delta,      â”‚â”‚
â”‚  â”‚                    â”‚                     â”‚    gorilla encoding)        â”‚â”‚
â”‚  â”‚ Query Language     â”‚ CQL (SELECT...)     â”‚ PromQL/Flux (rate(),       â”‚â”‚
â”‚  â”‚                    â”‚                     â”‚    derivative(), avg())     â”‚â”‚
â”‚  â”‚ Aggregations       â”‚ âŒ Client-side       â”‚ âœ… Native (percentiles,     â”‚â”‚
â”‚  â”‚                    â”‚                     â”‚    histograms, moving avg)  â”‚â”‚
â”‚  â”‚ Alerting           â”‚ âŒ Separate system   â”‚ âœ… Built-in (Alertmanager)  â”‚â”‚
â”‚  â”‚ Visualization      â”‚ âŒ Separate system   â”‚ âœ… Grafana integration      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  THE TOMBSTONE PROBLEM:                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Cassandra uses "tombstones" for deletes (marks as deleted, doesn't      â”‚
â”‚    actually remove until compaction)                                       â”‚
â”‚  â€¢ Metrics with TTL = constant deletes = tombstone buildup                 â”‚
â”‚  â€¢ Too many tombstones = slow reads, compaction storms                     â”‚
â”‚  â€¢ Time-series DBs handle retention natively (drop entire time blocks)     â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚                                                                              â”‚
â”‚  WHEN TO USE CASSANDRA FOR TIME-SERIES:                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  âœ… Already running Cassandra for other data                               â”‚
â”‚  âœ… Need raw event storage (not just numeric metrics)                      â”‚
â”‚  âœ… Very high cardinality (millions of unique tag combinations)            â”‚
â”‚  âœ… Need more query flexibility than TSDBs offer                           â”‚
â”‚  âœ… Multi-datacenter replication is critical                               â”‚
â”‚                                                                              â”‚
â”‚  WHEN TO USE TIME-SERIES DB:                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  âœ… Application/infrastructure monitoring                                  â”‚
â”‚  âœ… Need downsampling and retention out-of-the-box                         â”‚
â”‚  âœ… Want PromQL/Flux for time-based queries                                â”‚
â”‚  âœ… Integrated alerting and dashboards                                     â”‚
â”‚  âœ… Better compression = lower storage costs                               â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interview Talking Points

```
"For our monitoring system, we use Prometheus + Grafana because:
1. Pull-based model works well with Kubernetes service discovery
2. PromQL is powerful for alerting rules
3. Built-in alertmanager for notifications
4. Grafana provides rich visualization

For IoT sensor data, we chose TimescaleDB because:
1. SQL queries for complex analytics
2. Native PostgreSQL - existing team expertise
3. Continuous aggregates for real-time rollups
4. Compression reduces storage 90%+

Key considerations:
- Retention policies to manage storage costs
- Downsampling for historical data
- High-cardinality tags can explode storage"
```

---

## 7. OLTP vs OLAP

### The Two Worlds of Data Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OLTP vs OLAP                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  OLTP (Online Transaction Processing)                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  "The application database"                                                  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ INSERT this order                                                         â”‚
â”‚  â€¢ UPDATE user's email                                                       â”‚
â”‚  â€¢ SELECT user WHERE id = 123                                               â”‚
â”‚                                                                              â”‚
â”‚  Characteristics:                                                            â”‚
â”‚  â€¢ Short queries, few rows affected                                         â”‚
â”‚  â€¢ High concurrency (1000s of users)                                        â”‚
â”‚  â€¢ Low latency required (ms)                                                â”‚
â”‚  â€¢ Row-oriented storage                                                      â”‚
â”‚  â€¢ Normalized schema (3NF)                                                   â”‚
â”‚                                                                              â”‚
â”‚  Examples: PostgreSQL, MySQL, Oracle                                        â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  OLAP (Online Analytical Processing)                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  "The analytics database"                                                    â”‚
â”‚                                                                              â”‚
â”‚  â€¢ What was total revenue last quarter by region?                           â”‚
â”‚  â€¢ Which products have declining sales trend?                               â”‚
â”‚  â€¢ Customer cohort analysis over 2 years                                    â”‚
â”‚                                                                              â”‚
â”‚  Characteristics:                                                            â”‚
â”‚  â€¢ Long queries, millions of rows scanned                                   â”‚
â”‚  â€¢ Low concurrency (few analysts)                                           â”‚
â”‚  â€¢ High latency acceptable (seconds to minutes)                             â”‚
â”‚  â€¢ Column-oriented storage                                                   â”‚
â”‚  â€¢ Denormalized schema (Star/Snowflake)                                     â”‚
â”‚                                                                              â”‚
â”‚  Examples: Snowflake, BigQuery, Redshift, ClickHouse                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Side-by-Side Comparison

| Aspect | OLTP | OLAP |
|--------|------|------|
| **Purpose** | Run the business | Analyze the business |
| **Users** | Customers, apps | Analysts, data scientists |
| **Queries** | Simple, predefined | Complex, ad-hoc |
| **Data Size** | GBs to TBs | TBs to PBs |
| **Freshness** | Real-time | Hourly/daily batch |
| **Schema** | Normalized (3NF) | Denormalized (Star) |
| **Storage** | Row-oriented | Column-oriented |
| **Concurrency** | 1000s | 10s |
| **Latency** | Milliseconds | Seconds to minutes |

### Normalized vs Denormalized Schema (Why the difference?)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NORMALIZED SCHEMA (3NF) - OLTP                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  GOAL: Eliminate data redundancy, ensure data integrity                    â”‚
â”‚                                                                              â”‚
â”‚  Data is SPLIT into multiple related tables:                               â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   USERS     â”‚    â”‚     ORDERS      â”‚    â”‚  PRODUCTS   â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ user_id (PK)â”‚â—„â”€â”€â”€â”‚ user_id (FK)    â”‚    â”‚ product_id  â”‚                 â”‚
â”‚  â”‚ name        â”‚    â”‚ order_id (PK)   â”‚    â”‚ name        â”‚                 â”‚
â”‚  â”‚ email       â”‚    â”‚ product_id (FK) â”‚â”€â”€â”€â–ºâ”‚ price       â”‚                 â”‚
â”‚  â”‚ address     â”‚    â”‚ quantity        â”‚    â”‚ category    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ order_date      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                                                                              â”‚
â”‚  âœ… BENEFITS:                                                                â”‚
â”‚  â€¢ NO duplicate data (user email stored ONCE)                              â”‚
â”‚  â€¢ Update in ONE place (change email â†’ update 1 row)                       â”‚
â”‚  â€¢ Data consistency guaranteed                                              â”‚
â”‚  â€¢ Smaller storage footprint                                               â”‚
â”‚                                                                              â”‚
â”‚  âŒ DRAWBACKS:                                                               â”‚
â”‚  â€¢ Complex queries require JOINs (slower for analytics)                    â”‚
â”‚  â€¢ "Get order with user and product details" = 3-table JOIN                â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DENORMALIZED SCHEMA (Star) - OLAP                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  GOAL: Optimize for read performance, minimize JOINs                       â”‚
â”‚                                                                              â”‚
â”‚  Data is FLATTENED - redundant data is stored to avoid JOINs:              â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      ORDERS_FACT (Denormalized)                     â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ order_id | user_name | user_email | product_name | product_price | â”‚   â”‚
â”‚  â”‚          | product_category | quantity | order_date | region      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Same data, but ALL in one table (duplicated!):                            â”‚
â”‚  â€¢ order_1: "John", "john@email.com", "iPhone", $999, "Electronics"...    â”‚
â”‚  â€¢ order_2: "John", "john@email.com", "AirPods", $199, "Electronics"...   â”‚
â”‚  â€¢ order_3: "John", "john@email.com", "MacBook", $1999, "Electronics"...  â”‚
â”‚  (John's name and email repeated 3 times!)                                  â”‚
â”‚                                                                              â”‚
â”‚  âœ… BENEFITS:                                                                â”‚
â”‚  â€¢ FAST reads (no JOINs needed!)                                           â”‚
â”‚  â€¢ Simple queries: SELECT SUM(product_price) WHERE region = 'US'           â”‚
â”‚  â€¢ Optimized for aggregations (scan single table)                          â”‚
â”‚                                                                              â”‚
â”‚  âŒ DRAWBACKS:                                                               â”‚
â”‚  â€¢ Data redundancy (more storage)                                          â”‚
â”‚  â€¢ Updates are HARD (John changes email â†’ update ALL his orders!)          â”‚
â”‚  â€¢ Not suitable for OLTP (transactional) workloads                         â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WHY THIS TRADE-OFF MAKES SENSE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OLTP (Normalized):                                                        â”‚
â”‚  â€¢ Many small writes (INSERT order, UPDATE email)                          â”‚
â”‚  â€¢ Data changes frequently â†’ need single source of truth                   â”‚
â”‚  â€¢ JOINs are fine for small result sets (1 user, 1 order)                 â”‚
â”‚                                                                            â”‚
â”‚  OLAP (Denormalized):                                                      â”‚
â”‚  â€¢ Mostly reads, rare writes (batch ETL loads)                             â”‚
â”‚  â€¢ Data is historical (doesn't change after loaded)                        â”‚
â”‚  â€¢ Scanning millions of rows â†’ JOINs would be SLOW                         â”‚
â”‚  â€¢ Redundancy is acceptable for read performance                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Row vs Column Storage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ROW vs COLUMN STORAGE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  TABLE: sales (id, date, product, region, amount)                           â”‚
â”‚                                                                              â”‚
â”‚  ROW-ORIENTED (OLTP - PostgreSQL, MySQL):                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Stored as: [row1_all_columns][row2_all_columns][row3_all_columns]...       â”‚
â”‚                                                                              â”‚
â”‚  Disk:                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1|2024-01-15|Widget|US|100 â”‚ 2|2024-01-15|Gadget|EU|200 â”‚ ...      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  âœ… GOOD FOR: Fetch entire row (SELECT * WHERE id=1)                        â”‚
â”‚  âŒ BAD FOR: Aggregate one column (SUM(amount) for 1B rows)                 â”‚
â”‚              Must read ALL columns to get one column!                       â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  COLUMN-ORIENTED (OLAP - ClickHouse, Redshift, Parquet):                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Stored as: [all_ids][all_dates][all_products][all_regions][all_amounts]    â”‚
â”‚                                                                              â”‚
â”‚  Disk:                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ IDs:     1, 2, 3, 4, 5, ...                                         â”‚    â”‚
â”‚  â”‚ Dates:   2024-01-15, 2024-01-15, 2024-01-16, ...                    â”‚    â”‚
â”‚  â”‚ Products: Widget, Gadget, Widget, ...                               â”‚    â”‚
â”‚  â”‚ Regions: US, EU, US, ...                                            â”‚    â”‚
â”‚  â”‚ Amounts: 100, 200, 150, ...  â† Only read this for SUM!              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  âœ… GOOD FOR: Aggregate queries (read only columns needed)                  â”‚
â”‚  âœ… GOOD FOR: Compression (similar values together)                         â”‚
â”‚  âŒ BAD FOR: Fetch single row (must read from many files)                   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Warehouse Architecture: The Complete Story

Let me tell this as a story to connect all the dots.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHAPTER 1: THE PROBLEM                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  You have a PostgreSQL database running your e-commerce app.               â”‚
â”‚                                                                              â”‚
â”‚  One day, your CEO asks: "What was our revenue by region last quarter?"    â”‚
â”‚                                                                              â”‚
â”‚  You write this query on your OLTP database:                               â”‚
â”‚                                                                              â”‚
â”‚    SELECT region, SUM(amount)                                               â”‚
â”‚    FROM orders                                                              â”‚
â”‚    WHERE created_at > '2024-01-01'                                         â”‚
â”‚    GROUP BY region;                                                         â”‚
â”‚                                                                              â”‚
â”‚  PROBLEMS:                                                                   â”‚
â”‚  âŒ Query takes 30 minutes (scans millions of rows)                         â”‚
â”‚  âŒ Your production app slows down for users                                â”‚
â”‚  âŒ Analysts keep running these queries, app keeps crashing                 â”‚
â”‚                                                                              â”‚
â”‚  SOLUTION: Create a SEPARATE database for analytics!                       â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  OLTP Database  â”‚     Copy data      â”‚  OLAP Database  â”‚                 â”‚
â”‚  â”‚  (PostgreSQL)   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚  (Warehouse)    â”‚                 â”‚
â”‚  â”‚  For your app   â”‚      nightly       â”‚  For analysts   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                              â”‚
â”‚  Now analysts query the warehouse, app stays fast! âœ…                       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHAPTER 2: TRADITIONAL WAY (2010s)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  STEP 1: EXTRACT data from source databases                                â”‚
â”‚  STEP 2: Store raw data in HDFS                                            â”‚
â”‚  STEP 3: QUERY directly with Hive/Spark SQL (or transform + load)          â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚PostgreSQLâ”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚   HDFS   â”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚  Hive / Spark SQL               â”‚ â”‚
â”‚  â”‚  MySQL   â”‚       â”‚(storage) â”‚       â”‚  (query HDFS directly!)         â”‚ â”‚
â”‚  â”‚  Kafka   â”‚       â”‚          â”‚       â”‚                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  OR                             â”‚ â”‚
â”‚     EXTRACT           STORE            â”‚                                 â”‚ â”‚
â”‚                                        â”‚  Transform â†’ Load â†’ Warehouse  â”‚ â”‚
â”‚                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  WHAT IS HDFS?                                                              â”‚
â”‚  â€¢ Hadoop Distributed File System                                           â”‚
â”‚  â€¢ Just a way to store files across many machines                          â”‚
â”‚  â€¢ Like a giant hard drive spread across 100 servers                       â”‚
â”‚  â€¢ Stores files as Parquet, ORC, Avro (efficient formats)                  â”‚
â”‚  â€¢ You CANNOT query HDFS directly - need Spark/Hive on top!                â”‚
â”‚                                                                              â”‚
â”‚  PROBLEMS WITH TRADITIONAL:                                                 â”‚
â”‚  âŒ HDFS clusters are expensive (pay for servers 24/7)                      â”‚
â”‚  âŒ Complex to manage (need Hadoop admins)                                  â”‚
â”‚  âŒ Slow iteration (batch processing, not real-time)                       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHAPTER 3: MODERN WAY (2020s)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Replace HDFS with S3 (cloud blob storage), use managed warehouses.        â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚PostgreSQLâ”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚    S3    â”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚   dbt    â”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚Snowflake â”‚     â”‚
â”‚  â”‚  MySQL   â”‚       â”‚ (cheap!) â”‚       â”‚(transformâ”‚       â”‚ BigQuery â”‚     â”‚
â”‚  â”‚  Kafka   â”‚       â”‚          â”‚       â”‚ in SQL)  â”‚       â”‚ Redshift â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚     EXTRACT           STORE            TRANSFORM            QUERY          â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  WHAT IS S3?                                                                â”‚
â”‚  â€¢ Simple Storage Service (AWS) - just blob/file storage                   â”‚
â”‚  â€¢ Like Dropbox/Google Drive but for massive data                          â”‚
â”‚  â€¢ Pay only for what you store (no servers to manage!)                     â”‚
â”‚  â€¢ Azure Blob, Google Cloud Storage = same thing on other clouds           â”‚
â”‚                                                                              â”‚
â”‚  WHAT IS SNOWFLAKE/BIGQUERY/REDSHIFT?                                       â”‚
â”‚  â€¢ Cloud data warehouses (fully managed)                                    â”‚
â”‚  â€¢ You just write SQL, they handle everything                              â”‚
â”‚  â€¢ Columnar storage (fast for analytics)                                   â”‚
â”‚  â€¢ Pay per query or per compute time                                       â”‚
â”‚                                                                              â”‚
â”‚  WHY THIS IS BETTER:                                                        â”‚
â”‚  âœ… No servers to manage                                                    â”‚
â”‚  âœ… Pay only for what you use                                               â”‚
â”‚  âœ… Scale instantly                                                         â”‚
â”‚  âœ… Real-time streaming possible                                            â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  ğŸ’¡ SO SNOWFLAKE REPLACES HDFS + SPARK?                                     â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  TRADITIONAL (2010s)          â”‚  MODERN (2020s)                     â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  HDFS (storage)               â”‚  Snowflake storage (S3 internally) â”‚   â”‚
â”‚  â”‚  + Hive/Spark SQL (compute)   â”‚  + Snowflake compute (virtual WH)  â”‚   â”‚
â”‚  â”‚  + Manual management          â”‚  + Fully managed                   â”‚   â”‚
â”‚  â”‚  = You manage everything      â”‚  = Just write SQL!                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  YES, Snowflake bundles storage + compute + management into one service.  â”‚
â”‚                                                                              â”‚
â”‚  WHEN IS SPARK STILL USED?                                                  â”‚
â”‚  â€¢ Complex ETL (joins across 100s of tables, ML feature engineering)       â”‚
â”‚  â€¢ ML pipelines (training models on big data)                              â”‚
â”‚  â€¢ When you need more control than SQL provides                            â”‚
â”‚  â€¢ But for most analytics: Snowflake + dbt (SQL) is enough!               â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHAPTER 4: ALL TERMS SIMPLIFIED                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Term              â”‚  What It Actually Is                              â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚  S3/Blob Storage   â”‚  Cloud hard drive. Just stores files.            â”‚â”‚
â”‚  â”‚                    â”‚  Cannot query directly. Super cheap.              â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚  HDFS              â”‚  Old-school S3. Same idea but you manage servers.â”‚â”‚
â”‚  â”‚                    â”‚  Being replaced by S3 in most companies.          â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚  Data Warehouse    â”‚  Database optimized for analytics (Snowflake).   â”‚â”‚
â”‚  â”‚                    â”‚  Data is loaded, organized, fast to query.       â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚  Snowflake/BigQueryâ”‚  Cloud data warehouse. Fully managed.            â”‚â”‚
â”‚  â”‚  Redshift          â”‚  Write SQL, they handle compute/storage.         â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚  Spark             â”‚  Engine to process big data. Runs on HDFS/S3.    â”‚â”‚
â”‚  â”‚                    â”‚  Used for ETL (transform data).                   â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚  dbt               â”‚  Tool to write SQL transformations.               â”‚â”‚
â”‚  â”‚                    â”‚  Modern alternative to Spark for simple ETL.      â”‚â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
â”‚  â”‚  Parquet/ORC       â”‚  File formats optimized for analytics.            â”‚â”‚
â”‚  â”‚                    â”‚  Columnar, compressed. Store data in S3/HDFS.    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHAPTER 5: PUTTING IT ALL TOGETHER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  MODERN DATA ARCHITECTURE:                                                  â”‚
â”‚                                                                              â”‚
â”‚   SOURCES                STORAGE              TRANSFORM         SERVE       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                               â”‚
â”‚  â”‚PostgreSQLâ”‚â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚          â”‚        â”‚          â”‚     â”‚Dashboardsâ”‚  â”‚
â”‚                â”‚         â”‚   S3     â”‚        â”‚  dbt or  â”‚     â”‚ Tableau  â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (raw    â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Spark   â”‚â”€â”€â”€â”€â–ºâ”‚ Looker   â”‚  â”‚
â”‚  â”‚  Kafka   â”‚â”€â”€â”¤         â”‚  files)  â”‚        â”‚          â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚       â”‚
â”‚                â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                                   â–¼                â”‚       â”‚
â”‚  â”‚  APIs    â”‚â”€â”€â”˜                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚  Snowflake   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                            â”‚  (warehouse) â”‚                  â”‚
â”‚                                            â”‚  Query here! â”‚                  â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                   â”‚                          â”‚
â”‚                                                   â–¼                          â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                                            â”‚  ML Models   â”‚                  â”‚
â”‚                                            â”‚  Reports     â”‚                  â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                              â”‚
â”‚  TL;DR: Sources â†’ S3 (store) â†’ Transform â†’ Warehouse (query) â†’ Dashboards â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OLAP Databases Comparison

| Database | Type | Best For |
|----------|------|----------|
| **ClickHouse** | Column-store | Real-time analytics, time-series |
| **Snowflake** | Cloud DW | General analytics, variable workloads |
| **BigQuery** | Serverless | Ad-hoc queries, Google ecosystem |
| **Redshift** | Cloud DW | AWS ecosystem, Postgres-compatible |
| **Druid** | Real-time OLAP | Sub-second queries on streaming data |
| **Presto/Trino** | Query engine | Federated queries across sources |
| **Spark SQL** | Batch processing | ETL, ML pipelines |

---

## 8. Blob/Object Storage

### What is Object Storage?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBJECT STORAGE vs FILE STORAGE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  FILE STORAGE (NFS, EFS):                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  /home/                                                                      â”‚
â”‚  â”œâ”€â”€ user1/                                                                  â”‚
â”‚  â”‚   â”œâ”€â”€ documents/                                                         â”‚
â”‚  â”‚   â”‚   â””â”€â”€ report.pdf                                                     â”‚
â”‚  â”‚   â””â”€â”€ photos/                                                            â”‚
â”‚  â”‚       â””â”€â”€ vacation.jpg                                                   â”‚
â”‚  â””â”€â”€ user2/                                                                  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Hierarchical (directories and files)                                     â”‚
â”‚  â€¢ Supports file locking, permissions                                        â”‚
â”‚  â€¢ Limited scalability                                                       â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  OBJECT STORAGE (S3, GCS, Azure Blob):                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  Bucket: my-app-data                                                         â”‚
â”‚  Objects:                                                                    â”‚
â”‚    â€¢ Key: "users/123/profile.jpg"  â†’ Binary data + metadata                 â”‚
â”‚    â€¢ Key: "users/123/resume.pdf"   â†’ Binary data + metadata                 â”‚
â”‚    â€¢ Key: "logs/2024/01/15/app.log"â†’ Binary data + metadata                 â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Flat namespace (key â†’ value)                                             â”‚
â”‚  â€¢ "/" in key is just a character (no real directories!)                    â”‚
â”‚  â€¢ Immutable objects (versioning optional)                                  â”‚
â”‚  â€¢ Virtually unlimited scalability                                          â”‚
â”‚  â€¢ Eventual consistency (historically, now often strong)                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When to Use Object Storage

```
âœ… PERFECT FOR:
â”œâ”€â”€ User-generated content (images, videos, documents)
â”œâ”€â”€ Static assets (JS, CSS, images for web apps)
â”œâ”€â”€ Backups and archives
â”œâ”€â”€ Data lake storage (Parquet files for analytics)
â”œâ”€â”€ Log storage
â””â”€â”€ ML training data and models

âŒ NOT FOR:
â”œâ”€â”€ Transactional data (use a database)
â”œâ”€â”€ Frequently updated small files (high latency)
â”œâ”€â”€ Data requiring file locking
â””â”€â”€ Low-latency access patterns (consider caching)
```

### Object Storage Services Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OBJECT STORAGE OPTIONS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  AWS S3 (Simple Storage Service)                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ The "standard" (S3 API is de-facto industry standard)                    â”‚
â”‚  â€¢ Storage classes: Standard, Infrequent Access, Glacier (archival)         â”‚
â”‚  â€¢ Strong consistency (as of Dec 2020)                                      â”‚
â”‚  â€¢ Integrates with entire AWS ecosystem                                     â”‚
â”‚  â€¢ Pricing: ~$0.023/GB/month (Standard)                                     â”‚
â”‚                                                                              â”‚
â”‚  Google Cloud Storage (GCS)                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ S3-compatible API available                                              â”‚
â”‚  â€¢ Storage classes: Standard, Nearline, Coldline, Archive                   â”‚
â”‚  â€¢ Strong consistency                                                        â”‚
â”‚  â€¢ Best for: Google Cloud / BigQuery users                                  â”‚
â”‚                                                                              â”‚
â”‚  Azure Blob Storage                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Hot, Cool, Archive tiers                                                 â”‚
â”‚  â€¢ Best for: Azure ecosystem, Microsoft shops                               â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  LinkedIn Ambry                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ LinkedIn's open-source blob storage                                      â”‚
â”‚  â€¢ Designed for immutable media (images, videos)                            â”‚
â”‚  â€¢ Low latency, high throughput                                             â”‚
â”‚  â€¢ On-premise, not a cloud service                                          â”‚
â”‚  â€¢ Use case: Social media platforms with massive media                      â”‚
â”‚                                                                              â”‚
â”‚  MinIO                                                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ S3-compatible, self-hosted object storage                                â”‚
â”‚  â€¢ Open source, can run on Kubernetes                                       â”‚
â”‚  â€¢ Use case: On-premise, hybrid cloud, development                          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### S3 Access Patterns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMMON S3 PATTERNS                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. DIRECT UPLOAD (Pre-signed URLs)                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  Client â”€â”€â–º Your API â”€â”€â–º Generate Pre-signed URL                            â”‚
â”‚    â”‚                            â”‚                                            â”‚
â”‚    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚    â”‚         â”‚                                                               â”‚
â”‚    â”‚         â–¼                                                               â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â–º S3 (direct upload, bypasses your server)                        â”‚
â”‚                                                                              â”‚
â”‚  WHY: Don't proxy large files through your servers                          â”‚
â”‚                                                                              â”‚
â”‚  2. CDN IN FRONT (CloudFront + S3)                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  Client â”€â”€â–º CloudFront (CDN) â”€â”€â–º S3 (origin)                                â”‚
â”‚              â”‚                                                               â”‚
â”‚              â””â”€â”€ Caches at edge locations worldwide                          â”‚
â”‚                                                                              â”‚
â”‚  WHY: Reduce latency, reduce S3 costs (fewer requests)                      â”‚
â”‚                                                                              â”‚
â”‚  3. LIFECYCLE POLICIES                                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                              â”‚
â”‚  Day 0:   Object in S3 Standard ($0.023/GB)                                 â”‚
â”‚  Day 30:  Auto-transition to Infrequent Access ($0.0125/GB)                 â”‚
â”‚  Day 90:  Auto-transition to Glacier ($0.004/GB)                            â”‚
â”‚  Day 365: Auto-delete                                                        â”‚
â”‚                                                                              â”‚
â”‚  WHY: Automatic cost optimization for aging data                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interview Talking Points

```
"For user-uploaded images, we:
1. Generate a pre-signed S3 URL (client uploads directly)
2. Store metadata (user_id, filename, size) in PostgreSQL
3. Serve via CloudFront CDN for low latency
4. Use lifecycle policies: Standard â†’ IA after 30 days â†’ Glacier after 1 year

For our data lake:
1. Store raw events in S3 as Parquet files (columnar, compressed)
2. Partition by date: s3://data-lake/events/year=2024/month=01/day=15/
3. Query with Athena/Spark (no data movement)
4. Use Delta Lake for ACID transactions on object storage"
```

---

## 9. Decision Matrix

### Quick Reference Table

| Requirement | PostgreSQL | Cassandra | Redis | Kafka | Time-Series (InfluxDB) |
|-------------|------------|-----------|-------|-------|------------------------|
| ACID Transactions | âœ… | âŒ | âŒ | âŒ | âŒ |
| Complex Queries | âœ… | âŒ | âŒ | âŒ | âš ï¸ (time-based only) |
| High Write Throughput | âš ï¸ | âœ… | âœ… | âœ… | âœ… |
| Low Latency Reads | âš ï¸ | âš ï¸ | âœ… | âŒ | âœ… (recent data) |
| Horizontal Scale | âš ï¸ | âœ… | âš ï¸ | âœ… | âœ… |
| Durability | âœ… | âœ… | âš ï¸ | âœ… | âœ… |
| Global Distribution | âš ï¸ | âœ… | âš ï¸ | âš ï¸ | âš ï¸ |
| Message Replay | âŒ | âŒ | âŒ | âœ… | âŒ |
| Time-Range Queries | âš ï¸ | âš ï¸ | âŒ | âŒ | âœ… |
| Auto Downsampling | âŒ | âŒ | âŒ | âŒ | âœ… |

### Scenario-Based Selection

```
SCENARIO 1: E-Commerce Platform
â”œâ”€â”€ User accounts: PostgreSQL (ACID, complex queries)
â”œâ”€â”€ Product catalog: PostgreSQL + Elasticsearch (search)
â”œâ”€â”€ Shopping cart: Redis (fast, ephemeral)
â”œâ”€â”€ Order processing: PostgreSQL (transactions)
â”œâ”€â”€ Order events: Kafka (decouple inventory, shipping)
â””â”€â”€ Session storage: Redis (fast, TTL)

SCENARIO 2: Social Media Feed
â”œâ”€â”€ User profiles: PostgreSQL (relations, consistency)
â”œâ”€â”€ Posts: PostgreSQL (source of truth)
â”œâ”€â”€ Timeline cache: Redis (pre-computed feeds)
â”œâ”€â”€ Post events: Kafka (fan-out workers)
â”œâ”€â”€ Activity stream: Cassandra (time-series, write-heavy)
â””â”€â”€ Real-time updates: Redis Pub/Sub â†’ WebSocket

SCENARIO 3: IoT Sensor Platform
â”œâ”€â”€ Device registry: PostgreSQL (relations)
â”œâ”€â”€ Sensor readings: Cassandra (massive writes, time-series)
â”œâ”€â”€ Real-time dashboard: Redis (aggregations)
â”œâ”€â”€ Event pipeline: Kafka (sensor â†’ processing â†’ storage)
â””â”€â”€ Alerts: Kafka â†’ Alert service

SCENARIO 4: Financial Trading
â”œâ”€â”€ Accounts/Balances: PostgreSQL (ACID!)
â”œâ”€â”€ Trade execution: PostgreSQL (serializable transactions)
â”œâ”€â”€ Market data: Kafka (streaming prices)
â”œâ”€â”€ Order book cache: Redis (low latency)
â”œâ”€â”€ Audit log: Cassandra (append-only)
â””â”€â”€ Real-time prices: Kafka â†’ WebSocket

SCENARIO 5: Monitoring & Observability Platform
â”œâ”€â”€ User/Team config: PostgreSQL (relations, ACID)
â”œâ”€â”€ Metrics storage: Prometheus or InfluxDB (time-series)
â”œâ”€â”€ Logs storage: Elasticsearch (full-text search)
â”œâ”€â”€ Traces: Jaeger with Cassandra backend
â”œâ”€â”€ Dashboards: Grafana â†’ queries Prometheus/InfluxDB
â”œâ”€â”€ Alerts: Prometheus Alertmanager
â””â”€â”€ Long-term storage: S3 (downsampled metrics as Parquet)
```

---

## Interview Checklist

### Questions You Should Be Able to Answer

- [ ] "Why PostgreSQL and not Cassandra for user accounts?"
- [ ] "When would you choose Cassandra over PostgreSQL?"
- [ ] "Why use Redis when PostgreSQL can also cache?"
- [ ] "What's the difference between Redis and Kafka Pub/Sub?"
- [ ] "How would you design a system using all four?"
- [ ] "When would you use a time-series DB vs Cassandra for metrics?"
- [ ] "What's the difference between InfluxDB, Prometheus, and TimescaleDB?"

### Common Mistakes

| Mistake | Why It's Wrong |
|---------|----------------|
| "Kafka as a database" | Kafka is a log, not for queries |
| "Redis as primary storage" | Memory-only, use as cache layer |
| "Cassandra for transactions" | No ACID, use PostgreSQL |
| "PostgreSQL for 1M writes/sec" | Single-node limit, use Cassandra |
| "Cassandra for time-series metrics" | Works, but time-series DBs have downsampling, retention built-in |
| "PostgreSQL for high-cardinality metrics" | Not optimized, use InfluxDB/TimescaleDB |

---

## Next Steps

Continue to **[Level 6: Senior Gotchas](06_SENIOR_GOTCHAS.md)** for edge case interview questions.

